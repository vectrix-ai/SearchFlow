{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import vectrix\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Page Indexing and Vectorization üëÄ\n",
    "\n",
    "This Jupyter notebook contains a script that performs indexing and vectorization of web page contents. The primary purpose of this script is to crawl through a specified web page, extract the textual contents, and subsequently store these contents as vector objects in a database.\n",
    "\n",
    "The vectorized information can then be utilized in a Retrieval-Augmented Generation (RAG) flow to answer questions using a Language Model (LLM). This process enables the creation of a more context-aware and responsive system, capable of providing detailed responses based on the indexed and vectorized information from the web page.\n",
    "\n",
    "The notebook is structured in a step-by-step manner, guiding you through the process of web page crawling, text extraction, vectorization, and storage in a database. Each step is accompanied by detailed explanations and code snippets to provide a comprehensive understanding of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Crawler and Content Extractor\n",
    "\n",
    "This code implements a web crawler and content extractor that:\n",
    "\n",
    "1. Extracts URLs from the given HTML content, filtering for the same domain and validating the URLs. ‚úÖ\n",
    "2. Crawls a website starting from a given URL, iteratively processing and extracting links from each page. ‚úÖ\n",
    "3. Returns a mist of HTML documents extracted from the website ‚úÖ\n",
    "\n",
    "The code displays the source URL of each processed page and the total number of pages in the extracted content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = vectrix.Crawler(\"https://vectrix.ai\", max_pages=20)\n",
    "site_pages = crawler.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(site_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(site_pages[8].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Chunking\n",
    "In this step we will split all the extracted web pages into logical chunks. \n",
    "\n",
    "‚û°Ô∏è We will use the [trafilatura](https://trafilatura.readthedocs.io/en/latest/) library to extract the main content of the web pages. It will return the main content of the page, the title, and the meta description.\n",
    "\n",
    "‚û°Ô∏è We will pipe this to another splitter to further cut the sections into smaller chunks if they are too large. For this we use Langchains \n",
    "\n",
    "‚û°Ô∏è  Also we will attach an LLM to the chain to ignore chunks that are not relevant, for example: navigation bars, footers, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking and metadata extraction\n",
    "Using the functions below we extract the medata and devide the text into chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = vectrix.Webchunker(site_pages)\n",
    "chunks = chunker.chunk_content(chunk_size=500, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks[18].dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks[18].json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Extraction Pipeline\n",
    "Here we will use langchain and and LLM to extract the Named Entities from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = vectrix.Extract('Replicate', 'meta/meta-llama-3-70b-instruct')\n",
    "results = extractor.extract(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[4].dict()['metadata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the memory usage of this notebook\n",
    "import os\n",
    "import psutil\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory used: \", process.memory_info().rss / 1024 ** 2, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the result in a Weaviate (cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Vector store and check that all the required modules are installed\n",
    "\n",
    "Download the Docker compose file if needed\n",
    "```bash\n",
    "curl -o docker-compose.yml \"https://configuration.weaviate.io/v2/docker-compose/docker-compose.yml?cohere_key_approval=yes&generative_anyscale=false&generative_aws=false&generative_cohere=false&generative_mistral=false&generative_octoai=false&generative_ollama=false&generative_openai=false&generative_palm=false&media_type=text&modules=modules&ner_module=false&qna_module=false&ref2vec_centroid=false&reranker_cohere=true&reranker_cohere_key_approval=yes&reranker_transformers=false&runtime=docker-compose&spellcheck_module=true&spellcheck_module_model=pyspellchecker-en&sum_module=false&text_module=text2vec-cohere&weaviate_version=v1.25.4&weaviate_volume=named-volume\"\n",
    "```\n",
    "\n",
    "Make sure to set the persistent directory to the correct value:\n",
    "```bash\n",
    "    volumes:\n",
    "    - ~/weaviate_data:/var/lib/weaviate\n",
    "```\n",
    "\n",
    "Also configure the Cohere API key:\n",
    "```bash\n",
    "environment:\n",
    "      SPELLCHECK_INFERENCE_API: 'http://text-spellcheck:8080'\n",
    "      COHERE_APIKEY: ***\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from vectrix.db.weaviate import Weaviate, VectorDocument\n",
    "\n",
    "weaviate = Weaviate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.create_collection(name='Vectrix', \n",
    "                           embedding_model='Ollama', \n",
    "                           model_name=\"mxbai-embed-large:335m\",\n",
    "                           model_url=\"http://host.docker.internal:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vectrix']\n"
     ]
    }
   ],
   "source": [
    "print(weaviate.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.set_colleciton(name='Vectrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_vectorize = []\n",
    "\n",
    "for result in results:\n",
    "    data_to_vectorize.append(\n",
    "        VectorDocument(\n",
    "            title=result.metadata[\"title\"],\n",
    "            url=result.metadata[\"source\"],\n",
    "            content=result.page_content,\n",
    "            type=\"webpage\",\n",
    "            NER=str(result.metadata[\"NER\"]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "weaviate.add_data(data_to_vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'title': 'Vectrix', 'url': 'https://vectrix.ai/job-list/junior-ai-researcher', 'type': 'webpage'}, page_content='About Vectrix \\u200dVectrix is a cutting-edge AI startup dedicated to revolutionizing the field of generative AI solutions. Located in the vibrant heart of Antwerp, we strive to push the boundaries of artificial intelligence through innovative research and practical applications. \\u200d Position Overview \\u200dWe are currently seeking a passionate and skilled Junior AI Researcher to join our dynamic team. This role is ideal for someone who is deeply intrigued by the world of AI and eager to contribute to the development and deployment of groundbreaking AI technologies. \\u200d Key Responsibilities Collaborate with a team of experts to develop and refine generative AI models. Implement AI solutions using Python, focusing on robustness and scalability. Engage in the deployment of AI systems, ensuring smooth integration and functionality. Work with Google Cloud platforms to leverage cloud computing resources effectively. Contribute to research initiatives and stay updated with the latest trends in AI. \\u200d Qualifications Bachelor‚Äôs or Master‚Äôs degree in Computer Science, Artificial Intelligence, or a related field. Proficiency in Python programming, with a strong grasp of AI-related libraries and frameworks. Experience in deploying AI solutions, with a focus on practical and real-world applications. Hands-on experience with Google Cloud platforms is highly desirable. Excellent problem-solving skills and a keen interest in AI research and development. Ability to work collaboratively in a team and communicate effectively. \\u200d What We Offer A stimulating work environment in the heart of Antwerp. The opportunity to be part of a pioneering team in AI. Access to state-of-the-art technology and resources. A platform to grow your skills and career in the AI domain. Competitive salary and benefits.'),\n",
       "  '\\nHybrid (Result Set keyword,bm25) Document 982568c3-b9ea-47fc-9cfc-792f94af62dd: original score 1.1949081, normalized score: 0.16819042 - \\nHybrid (Result Set vector,hybridVector) Document 982568c3-b9ea-47fc-9cfc-792f94af62dd: original score 0.65125066, normalized score: 0.7399634'),\n",
       " (Document(metadata={'title': 'Vectrix', 'url': 'https://vectrix.ai/job-list/software-engineer-front-end', 'type': 'webpage'}, page_content='About Vectrix \\u200dVectrix is a cutting-edge AI startup dedicated to revolutionizing the field of generative AI solutions. Located in the vibrant heart of Antwerp, we strive to push the boundaries of artificial intelligence through innovative research and practical applications. \\u200d Position Overview \\u200dWe are eager to welcome a seasoned and proficient Senior Front-end Software Engineer to our dynamic team. This role is designed for professionals who are passionate about web technology and are looking to play a key role in crafting the future of user interfaces in AI-driven systems. \\u200d Key Responsibilities Lead the development and design of advanced, user-centric front-end interfaces for our AI solutions. Utilize and master the latest web technologies and frameworks to create responsive, high-performing applications. Uphold superior graphic standards and ensure brand consistency across our digital platforms. Collaborate closely with back-end developers to integrate AI features, ensuring an optimal user experience. Oversee code reviews, stay abreast of front-end development trends, and drive innovation for continual enhancements. \\u200d Qualifications Bachelor‚Äôs or Master‚Äôs degree in Computer Science, Web Development, or a related field, with significant professional experience. Expertise in front-end languages and frameworks, such as HTML, CSS, JavaScript, and advanced knowledge of React or Angular. Proven track record in building and managing responsive web applications, with an emphasis on aesthetic and functional design. Proficiency in version control tools like Git and experience with agile development processes. Exceptional problem-solving skills, a user-focused approach to solutions, and leadership abilities in a collaborative team setting. \\u200d What We Offer A stimulating work environment in the heart of Antwerp. The opportunity to be part of a pioneering team in AI. Access to state-of-the-art technology and resources. A platform to grow your skills and career in the AI domain. Competitive salary and benefits.'),\n",
       "  '\\nHybrid (Result Set keyword,bm25) Document 736102e1-a24e-455b-8366-c8d3d49c3fd5: original score 1.1025455, normalized score: 0.14895473 - \\nHybrid (Result Set vector,hybridVector) Document 736102e1-a24e-455b-8366-c8d3d49c3fd5: original score 0.64494264, normalized score: 0.7238308'),\n",
       " (Document(metadata={'title': 'Vectrix', 'url': 'https://vectrix.ai/job-list/internship', 'type': 'webpage'}, page_content=\"At Vectrix, we're passionate about cultivating a space where learning, innovation, and personal growth go hand-in-hand. We're on the lookout for diverse, enthusiastic talent who share our vision and are eager to make a tangible impact in the world of AI. Embark on a journey with Vectrix, where the exciting world of AI awaits you. With a spectrum of specialties and niches, there's a place for every interest. We value your ideas and initiative. Feel free to suggest topics you're passionate about or consider conducting your thesis under the mentorship of our seasoned team. What Vectrix is looking for: You're a student in Computer Science, Data Science, or a related field, looking for an energizing environment to work with the latest in data and machine learning tech. You've got a knack for analytics, are comfortable with mathematical concepts, and are intrigued by research. Your toolkit includes skills in Python, SQL, and other statistical analysis tools. Fluent in English, both written and spoken. Any experience with TensorFlow, PyTorch, or cloud deployment is a bonus. You're enthusiastic about starting your career on a strong note, and Vectrix is the perfect springboard for that! Please note: Our internships at Vectrix are designed to complement your academic journey. They are unpaid, as we focus on enriching your skills and career path. An internship agreement through your educational institution is essential to join us.\"),\n",
       "  '\\nHybrid (Result Set keyword,bm25) Document 6c59e89b-f85d-4fd4-9837-e2e6728f6e0b: original score 1.347646, normalized score: 0.19999999 - \\nHybrid (Result Set vector,hybridVector) Document 6c59e89b-f85d-4fd4-9837-e2e6728f6e0b: original score 0.6163801, normalized score: 0.65078276')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = weaviate.get_retriever()\n",
    "retriever.invoke('Who are the Vectrix founders ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.remove_collection(\"Vectrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
