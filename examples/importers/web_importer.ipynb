{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import vectrix\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Page Indexing and Vectorization ðŸ‘€\n",
    "\n",
    "This Jupyter notebook contains a script that performs indexing and vectorization of web page contents. The primary purpose of this script is to crawl through a specified web page, extract the textual contents, and subsequently store these contents as vector objects in a database.\n",
    "\n",
    "The vectorized information can then be utilized in a Retrieval-Augmented Generation (RAG) flow to answer questions using a Language Model (LLM). This process enables the creation of a more context-aware and responsive system, capable of providing detailed responses based on the indexed and vectorized information from the web page.\n",
    "\n",
    "The notebook is structured in a step-by-step manner, guiding you through the process of web page crawling, text extraction, vectorization, and storage in a database. Each step is accompanied by detailed explanations and code snippets to provide a comprehensive understanding of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Crawler and Content Extractor\n",
    "\n",
    "This code implements a web crawler and content extractor that:\n",
    "\n",
    "1. Extracts URLs from the given HTML content, filtering for the same domain and validating the URLs. âœ…\n",
    "2. Crawls a website starting from a given URL, iteratively processing and extracting links from each page. âœ…\n",
    "3. Returns a mist of HTML documents extracted from the website âœ…\n",
    "\n",
    "The code displays the source URL of each processed page and the total number of pages in the extracted content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  2.60it/s]\n",
      "Fetching pages: 100%|##########| 6/6 [00:01<00:00,  5.93it/s]\n",
      "Fetching pages: 100%|##########| 11/11 [00:02<00:00,  5.26it/s]\n"
     ]
    }
   ],
   "source": [
    "crawler = vectrix.Crawler(\"https://vectrix.ai\", max_pages=20)\n",
    "site_pages = crawler.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(site_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advice\n",
      "Vectrix Advice Services: Collaborative AI Solutions for Your Business\n",
      "AI Consultation and Strategic Advice\n",
      "Vectrix provides expert consultations to help businesses align their AI initiatives with their broader business strategies. This includes offering guidance on how to leverage AI for maximum impact, identifying opportunities for AI implementation, and advising on best practices for integrating AI into existing business processes.\n",
      "AI Readiness Assessment\n",
      "This service involves a comprehensive evaluation of a business's current systems and infrastructure to determine their readiness for AI integration. Vectrix assesses the potential for AI application within the organization and provides recommendations on how to prepare for and implement AI solutions effectively.\n",
      "Data Readiness and Optimization\n",
      "Recognizing the crucial role of data in AI deployments, Vectrix advises businesses on how to prepare their data for AI use. This includes assessing the current data infrastructure, advising on data management and structuring, and providing guidance on optimizing data to enhance the effectiveness of AI applications.\n",
      "Customization and Workflow Definition\n",
      "Vectrix offers assistance in tailoring AI integration to the specific needs of a business. This includes defining workflows, setting up decision trees, and customizing AI applications to align with the unique requirements and goals of the business.\n"
     ]
    }
   ],
   "source": [
    "print(site_pages[8].content['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Chunking\n",
    "In this step we will split all the extracted web pages into logical chunks. \n",
    "\n",
    "âž¡ï¸ We will use the [trafilatura](https://trafilatura.readthedocs.io/en/latest/) library to extract the main content of the web pages. It will return the main content of the page, the title, and the meta description.\n",
    "\n",
    "âž¡ï¸ We will pipe this to another splitter to further cut the sections into smaller chunks if they are too large. For this we use Langchains \n",
    "\n",
    "âž¡ï¸  Also we will attach an LLM to the chain to ignore chunks that are not relevant, for example: navigation bars, footers, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking and metadata extraction\n",
    "Using the functions below we extract the medata and devide the text into chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = vectrix.Webchunker(site_pages)\n",
    "chunks = chunker.chunk_content(chunk_size=500, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': None, 'metadata': {'source': 'https://vectrix.ai/blog-post/advanced-applications-and-future-trends-in-entity-analysis', 'title': 'Vectrix', 'language': 'en'}, 'page_content': \"can unlock new insights and make smarter decisions, enhancing our lives and business practices. What You Will Learn When Reading the Full Blog Post In the full blog post, you'll explore how entity analysis revolutionizes healthcare, finance, and legal services by extracting meaningful insights from data. You'll learn about real-world applications and the technical implementations driving these innovations. Additionally, discover future trends like real-time processing, multimodal analysis, and the integration of generative AI that promise to enhance personalization and decision-making in various fields. Whether you're looking for a technical deep dive or practical examples, the full post offers a comprehensive understanding of the potential and future of entity analysis.\", 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[18].dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": null,\n",
      "  \"metadata\": {\n",
      "    \"source\": \"https://vectrix.ai/blog-post/advanced-applications-and-future-trends-in-entity-analysis\",\n",
      "    \"title\": \"Vectrix\",\n",
      "    \"language\": \"en\"\n",
      "  },\n",
      "  \"page_content\": \"can unlock new insights and make smarter decisions, enhancing our lives and business practices. What You Will Learn When Reading the Full Blog Post In the full blog post, you'll explore how entity analysis revolutionizes healthcare, finance, and legal services by extracting meaningful insights from data. You'll learn about real-world applications and the technical implementations driving these innovations. Additionally, discover future trends like real-time processing, multimodal analysis, and the integration of generative AI that promise to enhance personalization and decision-making in various fields. Whether you're looking for a technical deep dive or practical examples, the full post offers a comprehensive understanding of the potential and future of entity analysis.\",\n",
      "  \"type\": \"Document\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[18].json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Extraction Pipeline\n",
    "Here we will use langchain and and LLM to extract the Named Entities from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:26<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "extractor = vectrix.Extract('Replicate', 'meta/meta-llama-3-70b-instruct')\n",
    "results = extractor.extract(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://vectrix.ai/platform', 'title': 'Vectrix - Platform', 'description': 'Our platform is your foundation for building unique generative AI applications that can enhance customer service, increase sales, and automate tasks. Dive into the extensive capabilities of our adaptable platform and discover how it can cater to your specific use case, integrating the transformative potential of AI directly into your business operations.', 'language': 'en', 'uuid': 'f8b4268c-2e8f-4ab9-a6aa-e16c959e4a9a', 'NER': {'entity_list': [{'entity_type': 'concept', 'entity_name': 'Small Language Models'}, {'entity_type': 'concept', 'entity_name': 'Large Language Models'}, {'entity_type': 'concept', 'entity_name': 'Artificial Intelligence'}, {'entity_type': 'location', 'entity_name': 'Virtual Private Cloud'}, {'entity_type': 'organization', 'entity_name': 'Apple Inc.'}], 'language': 'English', 'category': 'Artificial Intelligence'}}\n"
     ]
    }
   ],
   "source": [
    "print(results[4].dict()['metadata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used:  261.703125 MB\n"
     ]
    }
   ],
   "source": [
    "# Show the memory usage of this notebook\n",
    "import os\n",
    "import psutil\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory used: \", process.memory_info().rss / 1024 ** 2, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the result in a Weaviate (cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Vector store and check that all the required modules are installed\n",
    "\n",
    "Download the Docker compose file if needed\n",
    "```bash\n",
    "curl -o docker-compose.yml \"https://configuration.weaviate.io/v2/docker-compose/docker-compose.yml?cohere_key_approval=yes&generative_anyscale=false&generative_aws=false&generative_cohere=false&generative_mistral=false&generative_octoai=false&generative_ollama=false&generative_openai=false&generative_palm=false&media_type=text&modules=modules&ner_module=false&qna_module=false&ref2vec_centroid=false&reranker_cohere=true&reranker_cohere_key_approval=yes&reranker_transformers=false&runtime=docker-compose&spellcheck_module=true&spellcheck_module_model=pyspellchecker-en&sum_module=false&text_module=text2vec-cohere&weaviate_version=v1.25.4&weaviate_volume=named-volume\"\n",
    "```\n",
    "\n",
    "Make sure to set the persistent directory to the correct value:\n",
    "```bash\n",
    "    volumes:\n",
    "    - ~/weaviate_data:/var/lib/weaviate\n",
    "```\n",
    "\n",
    "Also configure the Cohere API key:\n",
    "```bash\n",
    "environment:\n",
    "      SPELLCHECK_INFERENCE_API: 'http://text-spellcheck:8080'\n",
    "      COHERE_APIKEY: ***\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectrix.db.weaviate import Weaviate, VectorDocument\n",
    "\n",
    "weaviate = Weaviate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.create_collection(name='Vectrix', \n",
    "                           embedding_model='Ollama', \n",
    "                           model_name=\"mxbai-embed-large:335m\",\n",
    "                           model_url=\"http://host.docker.internal:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weaviate.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.set_colleciton(name='Vectrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_vectorize = []\n",
    "\n",
    "for result in results:\n",
    "    data_to_vectorize.append(\n",
    "        VectorDocument(\n",
    "            title=result.metadata[\"title\"],\n",
    "            url=result.metadata[\"source\"],\n",
    "            content=result.page_content,\n",
    "            type=\"webpage\",\n",
    "            NER=str(result.metadata[\"NER\"]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "weaviate.add_data(data_to_vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = weaviate.get_retriever()\n",
    "retriever.invoke('Who are the Vectrix founders ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.remove_collection(\"Vectrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
