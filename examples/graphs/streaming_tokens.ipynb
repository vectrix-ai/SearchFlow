{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRAG-ReAct: Intelligent Retrieval Reasoning\n",
    "## Robust Retrieval-Augmented Generation with Step-by-Step Reasoning\n",
    "\n",
    "Welcome to this Jupyter notebook exploring cutting-edge techniques in artificial intelligence. We'll be diving into a powerful combination of two advanced approaches:\n",
    "\n",
    "1. **Corrective Retrieval Augmented Generation (CRAG)**\n",
    "2. **Reasoning+Acting (ReAct)**\n",
    "\n",
    "![Local image](./assets/RAG.png \"Flow Diagram\")\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "<small>\n",
    "\n",
    "**SOURCES:**\n",
    "\n",
    "[The paper](https://arxiv.org/abs/2210.03629) introduces ReAct, an approach that combines reasoning traces and task-specific actions in large language models (LLMs) to enhance their problem-solving capabilities. ReAct demonstrates improved performance, interpretability, and trustworthiness across various tasks, including question answering, fact verification, and interactive decision making, by allowing LLMs to generate reasoning steps and actions in an interleaved manner while interacting with external sources.\n",
    "\n",
    "\n",
    "[The Corrective Retrieval Augmented Generation (CRAG)](https://arxiv.org/abs/2401.15884) is a proposed approach to improve the robustness of language model generation by incorporating a lightweight retrieval evaluator, large-scale web searches, and a decompose-then-recompose algorithm for retrieved documents. CRAG aims to enhance the performance of RAG-based approaches by assessing retrieval quality, augmenting results with web searches when necessary, and selectively focusing on key information while filtering out irrelevant content.\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from paginx.graphs.demo import DemoGraph\n",
    "from paginx.db.chroma import Chroma\n",
    "from paginx.db.postgresql import PostgresSaver\n",
    "load_dotenv()\n",
    "\n",
    "# Enable langmsith tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the state\n",
    "The main type of graph in `langgraph` is the [StateGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph).\n",
    "This graph is parameterized by a `State` object that it passes around to each node.\n",
    "\n",
    "Each node then returns operations the graph uses to `update` that state.\n",
    "These operations can either SET specific attributes on the state (e.g. overwrite the existing values) or ADD to the existing attribute.\n",
    "Whether to set or add is denoted by annotating the `State` object you use to construct the graph.\n",
    "For this example, the state we will track will just be a list of messages.\n",
    "\n",
    "We want each node to just add messages to that list.\n",
    "\n",
    "Therefore, we will use a `TypedDict` with one key (`messages`) and annotate it so that the `messages` attribute is \\\"append-only\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_URI = \"postgresql://postgres:mysecretpassword@localhost/paginx?sslmode=disable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/GitHub/paginx/.venv/lib/python3.12/site-packages/psycopg_pool/pool_async.py:138: RuntimeWarning: opening the async pool AsyncConnectionPool in the constructor is deprecated and will not be supported anymore in a future release. Please use `await pool.open()`, or use the pool as context manager using: `async with AsyncConnectionPool(...) as pool: `...\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from psycopg_pool import AsyncConnectionPool\n",
    "\n",
    "pool = AsyncConnectionPool(\n",
    "    # Example configuration\n",
    "    conninfo=DB_URI,\n",
    "    max_size=20,\n",
    ")\n",
    "\n",
    "checkpointer = PostgresSaver(async_connection=pool)\n",
    "await checkpointer.acreate_tables(pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the tools\n",
    "\n",
    "We will first define the tools we want to use. For this simple example, we will use create a placeholder search engine. It is really easy to create your own tools - see documentation [here](https://python.langchain.com/v0.2/docs/how_to/custom_tools/) on how to do that.\n",
    "\n",
    "We will set-up a vector retriever and a search tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'excerpt': 'Established in 2023, Vectrix began as a small but ambitious team, aware of the growing demand for inventive, impactful solutions in the fast-paced digital era. Our expertise lies in blending creativity with generative AI technology to help businesses excel.', 'title': 'Vectrix - About Us', 'uuid': '3138a2fa-bcf2-4a4d-987d-67b813859396'}, page_content=\"AI Innovation Studio Advice Providing guidance on leveraging AI to advance your company with current technologies. Projects Products Meet team Vectrix Ben Selleslagh Co-Founder Meet Ben, a pivotal player and Co-Founder at Vectrix. With a rich background as a data professional, Ben brings his diverse experience from banking, government, and media sectors into the mix. He's skilled in crafting and executing data-driven strategies that sync perfectly with business goals. His expertise in Google Cloud technology makes him a wizard at building scalable and efficient data architectures. At Vectrix, Ben applies his know-how to innovate and drive our data and AI solutions, always with an eye on efficiency and scalability, ensuring that we stay at the forefront of AI technology. Dimitri Allaert Co-Founder Meet Dimitri Allaert, a driving force and Co-Founder at Vectrix. With roots in medical engineering and a history in the pharmaceutical world, Dimitri brings a different twist to our AI solutions. He kicked off his journey co-founding BUFFL, a market research platform, and then moved on in 2021 to dive into AI and emerging tech. At Vectrix, he's all about smart strategies and putting customers first, helping steer us towards exciting new developments in AI.\"), Document(metadata={'title': 'Job Description', 'uuid': '47bac497-384c-4f20-9f89-1accd31f5cab'}, page_content='About Vectrix \\u200dVectrix is a cutting-edge AI startup dedicated to revolutionizing the field of generative AI solutions. Located in the vibrant heart of Antwerp, we strive to push the boundaries of artificial intelligence through innovative research and practical applications. \\u200d Position Overview \\u200dWe are currently seeking a passionate and skilled Junior AI Researcher to join our dynamic team. This role is ideal for someone who is deeply intrigued by the world of AI and eager to contribute to the development and deployment of groundbreaking AI technologies. \\u200d Key Responsibilities Collaborate with a team of experts to develop and refine generative AI models. Implement AI solutions using Python, focusing on robustness and scalability. Engage in the deployment of AI systems, ensuring smooth integration and functionality. Work with Google Cloud platforms to leverage cloud computing resources effectively. Contribute to research initiatives and stay updated with the latest trends in AI. \\u200d Qualifications Bachelor’s or Master’s degree in Computer Science, Artificial Intelligence, or a related field. Proficiency in Python programming, with a strong grasp of AI-related libraries and frameworks. Experience in deploying AI solutions, with a focus on practical and real-world applications. Hands-on experience with Google Cloud platforms is highly desirable. Excellent problem-solving skills and a keen interest in AI research and development. Ability to work collaboratively in a team and communicate effectively. \\u200d What We Offer A stimulating work environment in the heart of Antwerp. The opportunity to be part of a pioneering team in AI. Access to state-of-the-art technology and resources. A platform to grow your skills and career in the AI domain. Competitive salary and benefits.'), Document(metadata={'title': 'Job Description', 'uuid': '12b7c9eb-6c3e-447e-b746-3cd840fbb27d'}, page_content=\"At Vectrix, we're passionate about cultivating a space where learning, innovation, and personal growth go hand-in-hand. We're on the lookout for diverse, enthusiastic talent who share our vision and are eager to make a tangible impact in the world of AI. Embark on a journey with Vectrix, where the exciting world of AI awaits you. With a spectrum of specialties and niches, there's a place for every interest. We value your ideas and initiative. Feel free to suggest topics you're passionate about or consider conducting your thesis under the mentorship of our seasoned team. What Vectrix is looking for: You're a student in Computer Science, Data Science, or a related field, looking for an energizing environment to work with the latest in data and machine learning tech. You've got a knack for analytics, are comfortable with mathematical concepts, and are intrigued by research. Your toolkit includes skills in Python, SQL, and other statistical analysis tools. Fluent in English, both written and spoken. Any experience with TensorFlow, PyTorch, or cloud deployment is a bonus. You're enthusiastic about starting your career on a strong note, and Vectrix is the perfect springboard for that! Please note: Our internships at Vectrix are designed to complement your academic journey. They are unpaid, as we focus on enriching your skills and career path. An internship agreement through your educational institution is essential to join us.\")]\n"
     ]
    }
   ],
   "source": [
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "# The vector retriever\n",
    "chroma = Chroma(CohereEmbeddings())\n",
    "vectorstore = chroma.load_db(os.getenv('CHROMA_DB_LOCATION'))\n",
    "print(vectorstore.similarity_search('Who are the founders of Vectrix', k=3))\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "# The tavily search tool\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now wrap these tools in a simple [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode)\n",
    "This is  a simple class that takes in a list of messages containing an [AIMessages with tool_calls](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.tool_calls), runs the tools, and returns the output as [ToolMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.tool.ToolMessage.html#langchain_core.messages.tool.ToolMessage)s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model\n",
    "\n",
    "Now we need to load the chat model we want to use. This should satisfy two criteria:\n",
    "\n",
    "1. It should work with messages, since our state is primarily a list of messages (chat history).\n",
    "2. It should work with tool calling, since we are using a prebuilt [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode)\n",
    "\n",
    "**Note:** these model requirements are not requirements for using LangGraph - they are just requirements for this particular example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, streaming=True)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"Who are the founders of Vectrix ?\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[0].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The founders of Vectrix are Ben Selleslagh and Dimitri Allaert. Ben has a background in data from banking, government, and media sectors, while Dimitri has roots in medical engineering and the pharmaceutical world. They co-founded Vectrix to innovate and drive data and AI solutions.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've done this, we should make sure the model knows that it has these tools available to call. We can do this by converting the LangChain tools into the format for function calling, and then bind them to the model class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who was the president before Joe Biden?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "'''\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "'''\n",
    "\n",
    "history = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"Who was the current president of the united states?\"),\n",
    "        (\"system\", \"The current president of the United States is Joe Biden.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "re_write_prompt = hub.pull(\"joeywhelan/rephrase\")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"input\": \"and the one before ?\", \"chat_history\": history})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the nodes\n",
    "\n",
    "We now need to define a few different nodes in our graph.\n",
    "In `langgraph`, a node can be either a function or a [runnable](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel).\n",
    "\n",
    "There are two main nodes we need for this:\n",
    "1. The agent: responsible for deciding what (if any) actions to take.\n",
    "2. A function to invoke tools: if the agent decides to take an action, this node will then execute that action.\n",
    "\n",
    "We will also need to define some edges.\n",
    "Some of these edges may be conditional.\n",
    "The reason they are conditional is that based on the output of a node, one of several paths may be taken.\n",
    "The path that is taken is not known until that node is run (the LLM decides).\n",
    "\n",
    "1. Conditional Edge: after the agent is called, we should either:\n",
    "    a. If the agent said to take an action, then the function to invoke tools should be called\n",
    "    b. If the agent said that it was finished, then it should finish\n",
    "2. Normal Edge: after the tools are invoked, it should always go back to the agent to decide what to do next\n",
    "\n",
    "Let's define the nodes, as well as a function to decide how what conditional edge to take.\n",
    "\n",
    "**STREAMING**\n",
    "\n",
    "We define each node as an async function.\n",
    "\n",
    "Manual Callback Propagation\n",
    "\n",
    "Note that in `call_model(state: State, config: RunnableConfig)`: below, we a) accept the RunnableConfig in the node and b) pass this in as the second arg for llm.ainvoke(..., config). This is optional for python 3.11 and later. If you ever have a problem where the LLM tokens are not streamed when using `astream_events` and you are using an older version of python, it's worth checking to ensure that the callbacks are manually propagated.\n",
    "\n",
    "### Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        messages: A list of messages\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]\n",
    "    question : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    # Add the question to the messages object\n",
    "    question = state[\"question\"]\n",
    "    # Retrieval\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "\n",
    "    # We return the document found and append the question to the messages\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "async def generate(state, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = await rag_chain.ainvoke({\"context\": documents, \"question\": question}, config)\n",
    "    #return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"input\": question, \"chat_history\": state[\"messages\"]})\n",
    "    return {\"documents\": documents, \"question\": better_question, \"messages\": question}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    print(question)\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"messages\"][-1]\n",
    "    web_search = state[\"web_search\"]\n",
    "    state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"web_search_node\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the graph\n",
    "\n",
    "We can now put it all togetehr and define the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "workflow.add_node(\"web_search_node\", web_search)  # web search\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"transform_query\")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"web_search_node\": \"web_search_node\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming LLM Tokens\n",
    "\n",
    "You can access the LLM tokens as they are produced by each node. In this case only the \"agent\" node produces LLM tokens. In order for this to work properly, you must be using an LLM that supports streaming as well as have set it when constructing the LLM (e.g. `ChatOpenAI(model=\"gpt-3.5-turbo-1106\", streaming=True)`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRANSFORM QUERY---\n",
      "What| are| the| first| names| of| the| founders| of| Vect|rix|?|---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "---WEB SEARCH---\n",
      "What are the first names of the founders of Vectrix?\n",
      "---GENERATE---\n",
      "Ben| and| Dimit|ri|"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "\n",
    "#input = HumanMessage(content=\"How's the weather in SF\")\n",
    "input = HumanMessage(content=\"I just want there first names\")\n",
    "\n",
    "async for event in app.astream_events({\"question\": input}, version=\"v1\", config=config):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI or Anthropic usually means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    '''\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_tuple = await checkpointer.aget_tuple(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST\n",
    "\n",
    "Here we will test the implemented code and see the LLM tokens produced by the agent node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from paginx.graphs.demo import DemoGraph\n",
    "\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "demo_graph = DemoGraph()\n",
    "graph = demo_graph.create_graph()\n",
    "\n",
    "inputs = [HumanMessage(content=\"Who are the founders of Vectrix ?\")]\n",
    "\n",
    "async for event in graph.astream_events({\"messages\": inputs}, version=\"v1\", config):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI or Anthropic usually means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paginx.graphs.vectrix import RAGWorkflowGraph\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "demo_graph = RAGWorkflowGraph()\n",
    "graph = demo_graph.create_graph()\n",
    "\n",
    "\n",
    "inputs = [HumanMessage(content=\"Who are the founders of Vectrix ?\")]\n",
    "\n",
    "async for event in graph.astream_events({\"messages\": inputs}, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI or Anthropic usually means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
