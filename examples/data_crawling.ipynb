{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import paginx\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Page Indexing and Vectorization 👀\n",
    "\n",
    "This Jupyter notebook contains a script that performs indexing and vectorization of web page contents. The primary purpose of this script is to crawl through a specified web page, extract the textual contents, and subsequently store these contents as vector objects in a database.\n",
    "\n",
    "The vectorized information can then be utilized in a Retrieval-Augmented Generation (RAG) flow to answer questions using a Language Model (LLM). This process enables the creation of a more context-aware and responsive system, capable of providing detailed responses based on the indexed and vectorized information from the web page.\n",
    "\n",
    "The notebook is structured in a step-by-step manner, guiding you through the process of web page crawling, text extraction, vectorization, and storage in a database. Each step is accompanied by detailed explanations and code snippets to provide a comprehensive understanding of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Crawler and Content Extractor\n",
    "\n",
    "This code implements a web crawler and content extractor that:\n",
    "\n",
    "1. Extracts URLs from the given HTML content, filtering for the same domain and validating the URLs. ✅\n",
    "2. Crawls a website starting from a given URL, iteratively processing and extracting links from each page. ✅\n",
    "3. Returns a mist of HTML documents extracted from the website ✅\n",
    "\n",
    "The code displays the source URL of each processed page and the total number of pages in the extracted content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Fetching pages: 100%|##########| 6/6 [00:01<00:00,  5.68it/s]\n",
      "Fetching pages: 100%|##########| 10/10 [00:01<00:00,  5.70it/s]\n"
     ]
    }
   ],
   "source": [
    "crawler = paginx.Crawler(\"https://vectrix.ai\")\n",
    "site_pages = crawler.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(site_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Job Description', 'author': None, 'hostname': None, 'date': None, 'fingerprint': '395059d9a3b4a234', 'id': None, 'license': None, 'comments': None, 'raw_text': \"At Vectrix, we're passionate about cultivating a space where learning, innovation, and personal growth go hand-in-hand. We're on the lookout for diverse, enthusiastic talent who share our vision and are eager to make a tangible impact in the world of AI. Embark on a journey with Vectrix, where the exciting world of AI awaits you. With a spectrum of specialties and niches, there's a place for every interest. We value your ideas and initiative. Feel free to suggest topics you're passionate about or consider conducting your thesis under the mentorship of our seasoned team. What Vectrix is looking for: You're a student in Computer Science, Data Science, or a related field, looking for an energizing environment to work with the latest in data and machine learning tech. You've got a knack for analytics, are comfortable with mathematical concepts, and are intrigued by research. Your toolkit includes skills in Python, SQL, and other statistical analysis tools. Fluent in English, both written and spoken. Any experience with TensorFlow, PyTorch, or cloud deployment is a bonus. You're enthusiastic about starting your career on a strong note, and Vectrix is the perfect springboard for that! Please note: Our internships at Vectrix are designed to complement your academic journey. They are unpaid, as we focus on enriching your skills and career path. An internship agreement through your educational institution is essential to join us.\", 'text': \"At Vectrix, we're passionate about cultivating a space where learning, innovation, and personal growth go hand-in-hand. We're on the lookout for diverse, enthusiastic talent who share our vision and are eager to make a tangible impact in the world of AI.\\nEmbark on a journey with Vectrix, where the exciting world of AI awaits you. With a spectrum of specialties and niches, there's a place for every interest.\\nWe value your ideas and initiative. Feel free to suggest topics you're passionate about or consider conducting your thesis under the mentorship of our seasoned team.\\nWhat Vectrix is looking for:\\nYou're a student in Computer Science, Data Science, or a related field, looking for an energizing environment to work with the latest in data and machine learning tech.\\n-\\nYou've got a knack for analytics, are comfortable with mathematical concepts, and are intrigued by research.\\n-\\nYour toolkit includes skills in Python, SQL, and other statistical analysis tools.\\n-\\nFluent in English, both written and spoken.\\n-\\nAny experience with TensorFlow, PyTorch, or cloud deployment is a bonus.\\n-\\nYou're enthusiastic about starting your career on a strong note, and Vectrix is the perfect springboard for that!\\n-\\nPlease note: Our internships at Vectrix are designed to complement your academic journey. They are unpaid, as we focus on enriching your skills and career path. An internship agreement through your educational institution is essential to join us.\", 'language': None, 'image': None, 'pagetype': None, 'filedate': '2024-07-18', 'source': None, 'source-hostname': None, 'excerpt': None, 'categories': '', 'tags': ''}\n"
     ]
    }
   ],
   "source": [
    "print(site_pages[8].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Chunking\n",
    "In this step we will split all the extracted web pages into logical chunks. \n",
    "\n",
    "➡️ We will use the [trafilatura](https://trafilatura.readthedocs.io/en/latest/) library to extract the main content of the web pages. It will return the main content of the page, the title, and the meta description.\n",
    "\n",
    "➡️ We will pipe this to another splitter to further cut the sections into smaller chunks if they are too large. For this we use Langchains \n",
    "\n",
    "➡️  Also we will attach an LLM to the chain to ignore chunks that are not relevant, for example: navigation bars, footers, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking and metadata extraction\n",
    "Using the functions below we extract the medata and devide the text into chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = paginx.Webchunker(site_pages)\n",
    "chunks = chunker.chunk_content(chunk_size=500, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': None, 'metadata': {'source': 'https://vectrix.ai/offerings/advice', 'title': 'Vectrix', 'language': 'en', 'uuid': '3eddac38-5e0b-4679-82a7-c7c42b47b178', 'NER': {'entity_list': [{'entity_type': 'organization', 'entity_name': 'Vectrix'}, {'entity_type': 'service', 'entity_name': 'AI Consultation and Strategic Advice'}, {'entity_type': 'service', 'entity_name': 'AI Readiness Assessment'}, {'entity_type': 'service', 'entity_name': 'Data Readiness and Optimization'}, {'entity_type': 'service', 'entity_name': 'Customization and Workflow Definition'}], 'language': 'English', 'category': 'AI Consultation Services'}, 'type': 'webpage'}, 'page_content': \"Advice Vectrix Advice Services: Collaborative AI Solutions for Your Business AI Consultation and Strategic Advice Vectrix provides expert consultations to help businesses align their AI initiatives with their broader business strategies. This includes offering guidance on how to leverage AI for maximum impact, identifying opportunities for AI implementation, and advising on best practices for integrating AI into existing business processes. AI Readiness Assessment This service involves a comprehensive evaluation of a business's current systems and infrastructure to determine their readiness for AI integration. Vectrix assesses the potential for AI application within the organization and provides recommendations on how to prepare for and implement AI solutions effectively. Data Readiness and Optimization Recognizing the crucial role of data in AI deployments, Vectrix advises businesses on how to prepare their data for AI use. This includes assessing the current data infrastructure, advising on data management and structuring, and providing guidance on optimizing data to enhance the effectiveness of AI applications. Customization and Workflow Definition Vectrix offers assistance in tailoring AI integration to the specific needs of a business. This includes defining workflows, setting up decision trees, and customizing AI applications to align with the unique requirements and goals of the business.\", 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[18].dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": null,\n",
      "  \"metadata\": {\n",
      "    \"source\": \"https://vectrix.ai/offerings/advice\",\n",
      "    \"title\": \"Vectrix\",\n",
      "    \"language\": \"en\"\n",
      "  },\n",
      "  \"page_content\": \"Advice Vectrix Advice Services: Collaborative AI Solutions for Your Business AI Consultation and Strategic Advice Vectrix provides expert consultations to help businesses align their AI initiatives with their broader business strategies. This includes offering guidance on how to leverage AI for maximum impact, identifying opportunities for AI implementation, and advising on best practices for integrating AI into existing business processes. AI Readiness Assessment This service involves a comprehensive evaluation of a business's current systems and infrastructure to determine their readiness for AI integration. Vectrix assesses the potential for AI application within the organization and provides recommendations on how to prepare for and implement AI solutions effectively. Data Readiness and Optimization Recognizing the crucial role of data in AI deployments, Vectrix advises businesses on how to prepare their data for AI use. This includes assessing the current data infrastructure, advising on data management and structuring, and providing guidance on optimizing data to enhance the effectiveness of AI applications. Customization and Workflow Definition Vectrix offers assistance in tailoring AI integration to the specific needs of a business. This includes defining workflows, setting up decision trees, and customizing AI applications to align with the unique requirements and goals of the business.\",\n",
      "  \"type\": \"Document\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[18].json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Extraction Pipeline\n",
    "Here we will use langchain and and LLM to extract the Named Entities from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities: 100%|██████████| 21/21 [00:16<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "extractor = paginx.Extract('Replicate', 'meta/meta-llama-3-70b-instruct')\n",
    "results = extractor.extract(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://vectrix.ai/platform', 'title': 'Vectrix - Platform', 'description': 'Our platform is your foundation for building unique generative AI applications that can enhance customer service, increase sales, and automate tasks. Dive into the extensive capabilities of our adaptable platform and discover how it can cater to your specific use case, integrating the transformative potential of AI directly into your business operations.', 'language': 'en', 'uuid': '7d32f9b5-eb70-4618-abdc-398236864890', 'NER': {'entity_list': [{'entity_type': 'concept', 'entity_name': 'Small Language Models'}, {'entity_type': 'concept', 'entity_name': 'Large Language Models'}, {'entity_type': 'concept', 'entity_name': 'Artificial Intelligence'}, {'entity_type': 'location', 'entity_name': 'Virtual Private Cloud'}, {'entity_type': 'organization', 'entity_name': 'Apple Inc.'}], 'language': 'English', 'category': 'Artificial Intelligence'}}\n"
     ]
    }
   ],
   "source": [
    "print(results[4].dict()['metadata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used:  268.21875 MB\n"
     ]
    }
   ],
   "source": [
    "# Show the memory usage of this notebook\n",
    "import os\n",
    "import psutil\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory used: \", process.memory_info().rss / 1024 ** 2, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the results in a Chroma DB Object\n",
    "Chroma is a fast and easy to use Vector database that can be used to load the retrieved content in memory and use a RAG-chain to retrieve the information. You can also persist the data in Chroma to disk for later use. We also use the langchain implementation to store the data in Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "chroma = paginx.Chroma(CohereEmbeddings())\n",
    "vector_db = chroma.create_db(results, os.getenv('CHROMA_DB_LOCATION'))\n",
    "\n",
    "# Let's perform a search and see of this works ...\n",
    "search_results = vector_db.similarity_search('Who are the founders of Vectrix ?, 3')\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = vector_db.similarity_search_with_score('Who are the founders of Vectrix ?, 3')\n",
    "\n",
    "for result in search_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the results in PostgreSQL (pgvector)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Pull the postgres image, install the pgvector extension and run the container\n",
    "!docker pull ankane/pgvector\n",
    "!docker run -d --name paginx -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 -e PG_EXTENSIONS=\"pgvector\" ankane/pgvector"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Connect to the default database (usually 'postgres')\n",
    "default_engine = create_engine('postgresql://postgres:mysecretpassword@localhost/postgres')\n",
    "\n",
    "# Create a new database named paginx if it doesn't exist\n",
    "with default_engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT 1 FROM pg_database WHERE datname = 'paginx'\"))\n",
    "    if not result.scalar():\n",
    "        connection.execute(text(\"COMMIT\"))  # Commit any open transactions\n",
    "        connection.execute(text(\"CREATE DATABASE paginx\"))\n",
    "\n",
    "# Connect to the newly created database\n",
    "paginx_engine = create_engine('postgresql://postgres:mysecretpassword@localhost/paginx')\n",
    "\n",
    "# Install the pgvector extension in the paginx database\n",
    "with paginx_engine.connect() as connection:\n",
    "    connection.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_postgres\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PGVector\n\u001b[1;32m      6\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgresql+psycopg://postgres:mysecretpassword@localhost/paginx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m collection_name \u001b[38;5;241m=\u001b[39m \u001b[43murl\u001b[49m\n\u001b[1;32m      8\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m CohereEmbeddings()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "connection = \"postgresql+psycopg://postgres:mysecretpassword@localhost/paginx\"\n",
    "collection_name = url\n",
    "embeddings = CohereEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstore.drop_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.add_documents(results, ids=[result.metadata[\"uuid\"] for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (vectorstore.similarity_search(\"When is the company founded ? \", k=3)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the result in a Weaviate (cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Vector store and check that all the required modules are installed\n",
    "\n",
    "Download the Docker compose file if needed\n",
    "```bash\n",
    "curl -o docker-compose.yml \"https://configuration.weaviate.io/v2/docker-compose/docker-compose.yml?cohere_key_approval=yes&generative_anyscale=false&generative_aws=false&generative_cohere=false&generative_mistral=false&generative_octoai=false&generative_ollama=false&generative_openai=false&generative_palm=false&media_type=text&modules=modules&ner_module=false&qna_module=false&ref2vec_centroid=false&reranker_cohere=true&reranker_cohere_key_approval=yes&reranker_transformers=false&runtime=docker-compose&spellcheck_module=true&spellcheck_module_model=pyspellchecker-en&sum_module=false&text_module=text2vec-cohere&weaviate_version=v1.25.4&weaviate_volume=named-volume\"\n",
    "```\n",
    "\n",
    "Make sure to set the persistent directory to the correct value:\n",
    "```bash\n",
    "    volumes:\n",
    "    - ~/weaviate_data:/var/lib/weaviate\n",
    "```\n",
    "\n",
    "Also configure the Cohere API key:\n",
    "```bash\n",
    "environment:\n",
    "      SPELLCHECK_INFERENCE_API: 'http://text-spellcheck:8080'\n",
    "      COHERE_APIKEY: ***\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hostname': 'http://[::]:8080', 'modules': {'reranker-cohere': {'documentationHref': 'https://txt.cohere.com/rerank/', 'name': 'Reranker - Cohere'}, 'text-spellcheck': {'model': {'name': 'pyspellchecker'}}, 'text2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/', 'name': 'Cohere Module'}}, 'version': '1.25.4'}\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "meta_info = client.get_meta()\n",
    "print(meta_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "client.collections.create(\n",
    "    \"webpages\",\n",
    "    # Additional parameters not shown\n",
    "    reranker_config=Configure.Reranker.cohere(\n",
    "        model=\"rerank-english-v3.0\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for collection in client.collections.list_all():\n",
    "    print(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': None, 'metadata': {'source': 'https://vectrix.ai/contact-us', 'title': 'Vectrix - Contact Us', 'description': 'Contact Us', 'language': 'en', 'uuid': '7f42662a-a1e4-41d0-bbee-889e2a90aee5', 'NER': {'entity_list': [{'entity_type': 'organization', 'entity_name': 'Vectrix'}], 'language': 'English', 'category': 'Artificial Intelligence'}}, 'page_content': \"At Vectrix, we specialize in training and validating Small Language Models (SLMs) on business data. Choose our platform for a DIY approach or collaborate with our experts. We make complex tech simple with tailored AI solutions. Ready to transform your work? Let's innovate together!\", 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "print(results[3].dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.collections.get(\"Vectrix\")\n",
    "\n",
    "with collection.batch.dynamic() as batch:\n",
    "    for result in results:\n",
    "        result.metadata[\"type\"] = \"webpage\"\n",
    "        weaviate_object = {\n",
    "            \"title\": result.dict()[\"metadata\"][\"title\"],\n",
    "            \"url\": result.dict()[\"metadata\"][\"source\"],\n",
    "            \"NER\": result.dict()[\"metadata\"][\"NER\"],\n",
    "            \"content\": result.dict()[\"page_content\"],\n",
    "            \"type\": \"webpage\",\n",
    "        }\n",
    "\n",
    "        batch.add_object(\n",
    "            properties=weaviate_object,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a (hybrid) search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectrix - About Us \n",
      "\n",
      "https://vectrix.ai/about-us \n",
      "\n",
      "webpage \n",
      "\n",
      "\n",
      "Hybrid (Result Set keyword,bm25) Document 86328141-c806-42b0-961a-2a293ef0ffd0: original score 0.53118104, normalized score: 0.037023842 - \n",
      "Hybrid (Result Set vector,hybridVector) Document 86328141-c806-42b0-961a-2a293ef0ffd0: original score 0.60171807, normalized score: 0.8\n",
      "Vectrix \n",
      "\n",
      "https://vectrix.ai/job-list/junior-ai-researcher \n",
      "\n",
      "webpage \n",
      "\n",
      "\n",
      "Hybrid (Result Set keyword,bm25) Document f1a2998f-a2b8-4104-bdec-e6daedb8d556: original score 1.2208344, normalized score: 0.17300671 - \n",
      "Hybrid (Result Set vector,hybridVector) Document f1a2998f-a2b8-4104-bdec-e6daedb8d556: original score 0.52417374, normalized score: 0.5775919\n",
      "Vectrix \n",
      "\n",
      "https://vectrix.ai/job-list/software-engineer-front-end \n",
      "\n",
      "webpage \n",
      "\n",
      "\n",
      "Hybrid (Result Set keyword,bm25) Document b3d8ed93-03be-4605-8570-275fbbcc18c7: original score 1.1256851, normalized score: 0.1542456 - \n",
      "Hybrid (Result Set vector,hybridVector) Document b3d8ed93-03be-4605-8570-275fbbcc18c7: original score 0.5012487, normalized score: 0.5118397\n"
     ]
    }
   ],
   "source": [
    "from weaviate.classes.query import MetadataQuery\n",
    "\n",
    "vectrix = client.collections.get(\"Vectrix\")\n",
    "response = vectrix.query.hybrid(\n",
    "    query=\"Who are the founders of Vectrix ?\",\n",
    "    alpha=0.8,\n",
    "    return_metadata=MetadataQuery(explain_score=True),\n",
    "    limit=3,\n",
    "    query_properties=['content']\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    #print(o.properties)\n",
    "    print(o.properties['title'], '\\n')\n",
    "    print(o.properties['url'], '\\n')\n",
    "    print(o.properties['type'], '\\n')\n",
    "    print(o.metadata.explain_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.delete(\"Vectrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
