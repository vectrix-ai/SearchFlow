{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import paginx\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Page Indexing and Vectorization ðŸ‘€\n",
    "\n",
    "This Jupyter notebook contains a script that performs indexing and vectorization of web page contents. The primary purpose of this script is to crawl through a specified web page, extract the textual contents, and subsequently store these contents as vector objects in a database.\n",
    "\n",
    "The vectorized information can then be utilized in a Retrieval-Augmented Generation (RAG) flow to answer questions using a Language Model (LLM). This process enables the creation of a more context-aware and responsive system, capable of providing detailed responses based on the indexed and vectorized information from the web page.\n",
    "\n",
    "The notebook is structured in a step-by-step manner, guiding you through the process of web page crawling, text extraction, vectorization, and storage in a database. Each step is accompanied by detailed explanations and code snippets to provide a comprehensive understanding of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Crawler and Content Extractor\n",
    "\n",
    "This code implements a web crawler and content extractor that:\n",
    "\n",
    "1. Extracts URLs from the given HTML content, filtering for the same domain and validating the URLs. âœ…\n",
    "2. Crawls a website starting from a given URL, iteratively processing and extracting links from each page. âœ…\n",
    "3. Returns a mist of HTML documents extracted from the website âœ…\n",
    "\n",
    "The code displays the source URL of each processed page and the total number of pages in the extracted content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  1.88it/s]\n",
      "Fetching pages: 100%|##########| 9/9 [00:01<00:00,  5.78it/s]\n",
      "Fetching pages: 100%|##########| 6/6 [00:01<00:00,  4.62it/s]\n"
     ]
    }
   ],
   "source": [
    "crawler = paginx.Crawler(\"https://vectrix.ai\")\n",
    "site_pages = crawler.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Vectrix - Contact Us',\n",
       " 'hostname': None,\n",
       " 'date': None,\n",
       " 'fingerprint': '3addcbe8f91e221e',\n",
       " 'id': None,\n",
       " 'license': None,\n",
       " 'comments': None,\n",
       " 'raw_text': 'At Vectrix, we specialize in using advanced technology, particularly generative AI, to transform the way businesses operate. Our focus is on simplifying complex processes, automating routine tasks, and designing unique, intuitive solutions that are easy to integrate and use.',\n",
       " 'text': 'At Vectrix, we specialize in using advanced technology, particularly generative AI, to transform the way businesses operate. Our focus is on simplifying complex processes, automating routine tasks, and designing unique, intuitive solutions that are easy to integrate and use.',\n",
       " 'language': None,\n",
       " 'image': None,\n",
       " 'pagetype': 'website',\n",
       " 'filedate': '2024-05-27',\n",
       " 'source': None,\n",
       " 'source_hostname': None,\n",
       " 'excerpt': 'Contact Us',\n",
       " 'categories': '',\n",
       " 'tags': ''}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_pages[2].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Chunking\n",
    "In this step we will split all the extracted web pages into logical chunks. \n",
    "\n",
    "âž¡ï¸ We will use the [trafilatura](https://trafilatura.readthedocs.io/en/latest/) library to extract the main content of the web pages. It will return the main content of the page, the title, and the meta description.\n",
    "\n",
    "âž¡ï¸ We will pipe this to another splitter to further cut the sections into smaller chunks if they are too large. For this we use Langchains \n",
    "\n",
    "âž¡ï¸  Also we will attach an LLM to the chain to ignore chunks that are not relevant, for example: navigation bars, footers, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking and metadata extraction\n",
    "Using the functions below we extract the medata and devide the text into chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = paginx.Webchunker(site_pages)\n",
    "chunks = chunker.chunk_content(chunk_size=500, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"page_content\": \"At Vectrix, we specialize in using advanced technology, particularly generative AI, to transform the way businesses operate. Our focus is on simplifying complex processes, automating routine tasks, and designing unique, intuitive solutions that are easy to integrate and use.\",\n",
      "  \"metadata\": {\n",
      "    \"title\": \"Vectrix - Contact Us\",\n",
      "    \"hostname\": null,\n",
      "    \"image\": null,\n",
      "    \"source\": null,\n",
      "    \"source_hostname\": null,\n",
      "    \"excerpt\": \"Contact Us\"\n",
      "  },\n",
      "  \"type\": \"Document\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[2].json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Extraction Pipeline\n",
    "Here we will use langchain and and LLM to extract the Named Entities from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:21<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "extractor = paginx.Extract('Replicate', 'meta/meta-llama-3-70b-instruct')\n",
    "results = extractor.extract(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[3].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used:  276.625 MB\n"
     ]
    }
   ],
   "source": [
    "# Show the memory usage of this notebook\n",
    "import os\n",
    "import psutil\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory used: \", process.memory_info().rss / 1024 ** 2, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the results in a Chroma DB Object\n",
    "Chroma is a fast and easy to use Vector database that can be used to load the retrieved content in memory and use a RAG-chain to retrieve the information. You can also persist the data in Chroma to disk for later use. We also use the langchain implementation to store the data in Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"page_content\": \"AI Innovation Studio Meet team Vectrix Ben Selleslagh Co-Founder Meet Ben, a pivotal player and Co-Founder at Vectrix. With a rich background as a data professional, Ben brings his diverse experience from banking, government, and media sectors into the mix. He's skilled in crafting and executing data-driven strategies that sync perfectly with business goals. His expertise in Google Cloud technology makes him a wizard at building scalable and efficient data architectures. At Vectrix, Ben applies his know-how to innovate and drive our data and AI solutions, always with an eye on efficiency and scalability, ensuring that we stay at the forefront of AI technology. Dimitri Allaert Co-Founder Meet Dimitri Allaert, a driving force and Co-Founder at Vectrix. With roots in medical engineering and a history in the pharmaceutical world, Dimitri brings a different twist to our AI solutions. He kicked off his journey co-founding BUFFL, a market research platform, and then moved on in 2021 to dive into AI and emerging tech. At Vectrix, he's all about smart strategies and putting customers first, helping steer us towards exciting new developments in AI.\",\n",
      "  \"metadata\": {\n",
      "    \"excerpt\": \"Established in 2023, Vectrix began as a small but ambitious team, aware of the growing demand for inventive, impactful solutions in the fast-paced digital era. Our expertise lies in blending creativity with generative AI technology to help businesses excel.\",\n",
      "    \"title\": \"Vectrix - About Us\",\n",
      "    \"uuid\": \"edbd5684-6ea2-4789-b24d-33d72e55a608\"\n",
      "  },\n",
      "  \"type\": \"Document\"\n",
      "}\n",
      "{\n",
      "  \"page_content\": \"About Vectrix \\u200dVectrix is a cutting-edge AI startup dedicated to revolutionizing the field of generative AI solutions. Located in the vibrant heart of Antwerp, we strive to push the boundaries of artificial intelligence through innovative research and practical applications. \\u200d Position Overview \\u200dWe are currently seeking a passionate and skilled Junior AI Researcher to join our dynamic team. This role is ideal for someone who is deeply intrigued by the world of AI and eager to contribute to the development and deployment of groundbreaking AI technologies. \\u200d Key Responsibilities Collaborate with a team of experts to develop and refine generative AI models. Implement AI solutions using Python, focusing on robustness and scalability. Engage in the deployment of AI systems, ensuring smooth integration and functionality. Work with Google Cloud platforms to leverage cloud computing resources effectively. Contribute to research initiatives and stay updated with the latest trends in AI. \\u200d Qualifications Bachelor\\u2019s or Master\\u2019s degree in Computer Science, Artificial Intelligence, or a related field. Proficiency in Python programming, with a strong grasp of AI-related libraries and frameworks. Experience in deploying AI solutions, with a focus on practical and real-world applications. Hands-on experience with Google Cloud platforms is highly desirable. Excellent problem-solving skills and a keen interest in AI research and development. Ability to work collaboratively in a team and communicate effectively. \\u200d What We Offer A stimulating work environment in the heart of Antwerp. The opportunity to be part of a pioneering team in AI. Access to state-of-the-art technology and resources. A platform to grow your skills and career in the AI domain. Competitive salary and benefits.\",\n",
      "  \"metadata\": {\n",
      "    \"title\": \"Job Description\",\n",
      "    \"uuid\": \"c8fb258c-1b47-4946-afdc-813f49c5661b\"\n",
      "  },\n",
      "  \"type\": \"Document\"\n",
      "}\n",
      "{\n",
      "  \"page_content\": \"At Vectrix, we're passionate about cultivating a space where learning, innovation, and personal growth go hand-in-hand. We're on the lookout for diverse, enthusiastic talent who share our vision and are eager to make a tangible impact in the world of AI. Embark on a journey with Vectrix, where the exciting world of AI awaits you. With a spectrum of specialties and niches, there's a place for every interest. We value your ideas and initiative. Feel free to suggest topics you're passionate about or consider conducting your thesis under the mentorship of our seasoned team. What Vectrix is looking for: You're a student in Computer Science, Data Science, or a related field, looking for an energizing environment to work with the latest in data and machine learning tech. You've got a knack for analytics, are comfortable with mathematical concepts, and are intrigued by research. Your toolkit includes skills in Python, SQL, and other statistical analysis tools. Fluent in English, both written and spoken. Any experience with TensorFlow, PyTorch, or cloud deployment is a bonus. You're enthusiastic about starting your career on a strong note, and Vectrix is the perfect springboard for that! Please note: Our internships at Vectrix are designed to complement your academic journey. They are unpaid, as we focus on enriching your skills and career path. An internship agreement through your educational institution is essential to join us.\",\n",
      "  \"metadata\": {\n",
      "    \"title\": \"Job Description\",\n",
      "    \"uuid\": \"c4f98a10-6907-45a4-8ec3-dfc3bd82bc7a\"\n",
      "  },\n",
      "  \"type\": \"Document\"\n",
      "}\n",
      "{\n",
      "  \"page_content\": \"About Vectrix \\u200dVectrix is a cutting-edge AI startup dedicated to revolutionizing the field of generative AI solutions. Located in the vibrant heart of Antwerp, we strive to push the boundaries of artificial intelligence through innovative research and practical applications. \\u200d Position Overview \\u200dWe are eager to welcome a seasoned and proficient Senior Front-end Software Engineer to our dynamic team. This role is designed for professionals who are passionate about web technology and are looking to play a key role in crafting the future of user interfaces in AI-driven systems. \\u200d Key Responsibilities Lead the development and design of advanced, user-centric front-end interfaces for our AI solutions. Utilize and master the latest web technologies and frameworks to create responsive, high-performing applications. Uphold superior graphic standards and ensure brand consistency across our digital platforms. Collaborate closely with back-end developers to integrate AI features, ensuring an optimal user experience. Oversee code reviews, stay abreast of front-end development trends, and drive innovation for continual enhancements. \\u200d Qualifications Bachelor\\u2019s or Master\\u2019s degree in Computer Science, Web Development, or a related field, with significant professional experience. Expertise in front-end languages and frameworks, such as HTML, CSS, JavaScript, and advanced knowledge of React or Angular. Proven track record in building and managing responsive web applications, with an emphasis on aesthetic and functional design. Proficiency in version control tools like Git and experience with agile development processes. Exceptional problem-solving skills, a user-focused approach to solutions, and leadership abilities in a collaborative team setting. \\u200d What We Offer A stimulating work environment in the heart of Antwerp. The opportunity to be part of a pioneering team in AI. Access to state-of-the-art technology and resources. A platform to grow your skills and career in the AI domain. Competitive salary and benefits.\",\n",
      "  \"metadata\": {\n",
      "    \"title\": \"Job Description\",\n",
      "    \"uuid\": \"a04f12f7-d0bf-4777-8648-be85a42ccad2\"\n",
      "  },\n",
      "  \"type\": \"Document\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chroma = paginx.Chroma(results)\n",
    "chroma = chroma.return_db_object()\n",
    "\n",
    "# Let's perform a search and see of this works ...\n",
    "search_results = chroma.similarity_search('Who are the founders of Vectrix ?, 3')\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the results in PostgreSQL (pgvector)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Pull the postgres image, install the pgvector extension and run the container\n",
    "!docker pull ankane/pgvector\n",
    "!docker run -d --name paginx -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 -e PG_EXTENSIONS=\"pgvector\" ankane/pgvector"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Connect to the default database (usually 'postgres')\n",
    "default_engine = create_engine('postgresql://postgres:mysecretpassword@localhost/postgres')\n",
    "\n",
    "# Create a new database named paginx if it doesn't exist\n",
    "with default_engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT 1 FROM pg_database WHERE datname = 'paginx'\"))\n",
    "    if not result.scalar():\n",
    "        connection.execute(text(\"COMMIT\"))  # Commit any open transactions\n",
    "        connection.execute(text(\"CREATE DATABASE paginx\"))\n",
    "\n",
    "# Connect to the newly created database\n",
    "paginx_engine = create_engine('postgresql://postgres:mysecretpassword@localhost/paginx')\n",
    "\n",
    "# Install the pgvector extension in the paginx database\n",
    "with paginx_engine.connect() as connection:\n",
    "    connection.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "connection = \"postgresql+psycopg://postgres:mysecretpassword@localhost/paginx\"\n",
    "collection_name = url\n",
    "embeddings = CohereEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstore.drop_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.add_documents(results, ids=[result.metadata[\"uuid\"] for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (vectorstore.similarity_search(\"When is the company founded ? \", k=3)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
