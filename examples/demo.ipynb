{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", ResourceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectrix Demo üë®üèª‚Äçüíª\n",
    "This notebook demonstrates the functions for importing data from various sources. \n",
    "Loading it into a VectorStore, and then using it to answer questions with a Retrieval Augemented Reasoning  ü¶úüîó LangGraph.\n",
    "\n",
    "## Importing Data\n",
    "### 1. From a URL üîó\n",
    "\n",
    "**Web Crawling and Data Extraction Example**\n",
    "\n",
    "This cell demonstrates the process of crawling a website, chunking the extracted content, and performing Named Entity Recognition (NER) using the Vectrix library.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. **Web Crawling**: \n",
    "   - Uses `vectrix.Crawler` to extract pages from \"https://vectrix.ai\"\n",
    "   - Limits the crawl to a maximum of 20 pages\n",
    "\n",
    "2. **Content Chunking**:\n",
    "   - Utilizes `vectrix.Webchunker` to break down the extracted content\n",
    "   - Chunks are created with a size of 500 characters and an overlap of 50 characters\n",
    "\n",
    "3. **Named Entity Recognition**:\n",
    "   - Employs `vectrix.Extract` with the 'Replicate' model\n",
    "   - Uses the 'meta/meta-llama-3-70b-instruct' model for entity extraction\n",
    "\n",
    "This example showcases a typical workflow for web data extraction and processing using the Vectrix library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "INFO:root:Starting extraction for site: vectrix.ai\n",
      "\u001b[32m2024-08-08 11:33:01,163 - root - INFO - Starting extraction for site: vectrix.ai\u001b[0m\n",
      "Fetching pages: 100%|##########| 1/1 [00:01<00:00,  1.23s/it]\n",
      "INFO:root:Visiting links: ['https://vectrix.ai/offerings', 'https://vectrix.ai/blog', 'https://vectrix.ai/blog-post/google-deepminds-searchless-chess-engine---part-1', 'https://vectrix.ai/blog-post/advanced-applications-and-future-trends-in-entity-analysis', 'https://vectrix.ai/blog-post/understanding-large-and-small-language-models-key-differences-and-applications', 'https://vectrix.ai/blog-post/are-llm-benchmarks-and-leaderboards-just-marketing-tools', 'https://vectrix.ai/career', 'https://vectrix.ai/platform', 'https://vectrix.ai/contact-us', 'https://vectrix.ai/about-us']\n",
      "\u001b[32m2024-08-08 11:33:02,425 - root - INFO - Visiting links: ['https://vectrix.ai/offerings', 'https://vectrix.ai/blog', 'https://vectrix.ai/blog-post/google-deepminds-searchless-chess-engine---part-1', 'https://vectrix.ai/blog-post/advanced-applications-and-future-trends-in-entity-analysis', 'https://vectrix.ai/blog-post/understanding-large-and-small-language-models-key-differences-and-applications', 'https://vectrix.ai/blog-post/are-llm-benchmarks-and-leaderboards-just-marketing-tools', 'https://vectrix.ai/career', 'https://vectrix.ai/platform', 'https://vectrix.ai/contact-us', 'https://vectrix.ai/about-us']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Started', 'pages_scraped': 0, 'total_links': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 10/10 [00:05<00:00,  1.80it/s]\n",
      "INFO:root:Pages processed: 10\n",
      "\u001b[32m2024-08-08 11:33:08,036 - root - INFO - Pages processed: 10\u001b[0m\n",
      "INFO:root:Links to visit: 13\n",
      "\u001b[32m2024-08-08 11:33:08,064 - root - INFO - Links to visit: 13\u001b[0m\n",
      "INFO:root:Visiting links: ['https://vectrix.ai/offerings/chat-ui', 'https://vectrix.ai/offerings/advice', 'https://vectrix.ai/offerings/projects', 'https://vectrix.ai/blog-post/the-basics-of-entity-analysis-beyond-just-identifying-names', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/job-list/software-engineer-front-end', 'https://vectrix.ai/job-list/open-application---create-your-own-dream-job', 'https://vectrix.ai/job-list/junior-ai-researcher', 'https://vectrix.ai/job-list/internship', 'https://www.vectrix.ai/offerings']\n",
      "\u001b[32m2024-08-08 11:33:08,066 - root - INFO - Visiting links: ['https://vectrix.ai/offerings/chat-ui', 'https://vectrix.ai/offerings/advice', 'https://vectrix.ai/offerings/projects', 'https://vectrix.ai/blog-post/the-basics-of-entity-analysis-beyond-just-identifying-names', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/job-list/software-engineer-front-end', 'https://vectrix.ai/job-list/open-application---create-your-own-dream-job', 'https://vectrix.ai/job-list/junior-ai-researcher', 'https://vectrix.ai/job-list/internship', 'https://www.vectrix.ai/offerings']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'In progress', 'pages_scraped': 10, 'links_remaining': 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 13/13 [00:07<00:00,  1.84it/s]\n",
      "INFO:root:Pages processed: 23\n",
      "\u001b[32m2024-08-08 11:33:15,180 - root - INFO - Pages processed: 23\u001b[0m\n",
      "INFO:root:Links to visit: 0\n",
      "\u001b[32m2024-08-08 11:33:15,226 - root - INFO - Links to visit: 0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'In progress', 'pages_scraped': 23, 'links_remaining': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:SCRAPING FINISHED: Pages extracted 24\n",
      "\u001b[32m2024-08-08 11:33:15,713 - root - INFO - SCRAPING FINISHED: Pages extracted 24\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Finished', 'pages_scraped': 24}\n",
      "Total documents: 24\n"
     ]
    }
   ],
   "source": [
    "from vectrix.importers import WebCrawler\n",
    "\n",
    "url = \"https://vectrix.ai\"\n",
    "\n",
    "crawler = WebCrawler(url)\n",
    "generator = crawler.extract()\n",
    "scraped_pages = []\n",
    "\n",
    "# Iterate through progress updates\n",
    "for item in generator:\n",
    "    if isinstance(item, dict):\n",
    "        print(item)  # This is a progress update\n",
    "    else:\n",
    "        scraped_pages.extend(item)  # This is the final list of Documents\n",
    "        break\n",
    "\n",
    "# Now final_result contains the list of Documents\n",
    "print(f\"Total documents: {len(scraped_pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://vectrix.ai/offerings\n",
      "Our Offerings\n",
      "Project that challenge force\n",
      "Working with Alex was interesting. He haveing into went beyond what asking provided such an amazing.\n",
      "Project that challenge force\n",
      "Working with Alex was inter\n",
      "https://vectrix.ai/blog\n",
      "Vectrix AI Insights: Trends, Innovations, and Updates\n",
      "Explore the latest in AI with Vectrix Insights. Our blog covers trends, detailed looks at SLMs and LLMs, and real-world applications. Stay updated\n",
      "https://vectrix.ai/blog-post/google-deepminds-searchless-chess-engine---part-1\n",
      "Google DeepMind‚Äôs Searchless Chess Engine - Part 1\n",
      "Dimitri Allaert\n",
      "Introduction:\n",
      "Discover how Google DeepMind‚Äôs Searchless Chess Engine, utilizing deep neural networks without traditional search metho\n",
      "https://vectrix.ai/blog-post/advanced-applications-and-future-trends-in-entity-analysis\n",
      "Advanced Applications and Future Trends in Entity Analysis\n",
      "Dimitri Allaert\n",
      "Entity analysis is transforming industries by turning raw data into actionable insights. This technology enhances patient car\n",
      "https://vectrix.ai/blog-post/understanding-large-and-small-language-models-key-differences-and-applications\n",
      "Understanding Large and Small Language Models: Key Differences and Applications\n",
      "Dimitri Allaert\n",
      "Imagine chatting with a friend who always knows what you‚Äôre trying to say, offering spot-on advice. This\n",
      "https://vectrix.ai/blog-post/are-llm-benchmarks-and-leaderboards-just-marketing-tools\n",
      "Are LLM Benchmarks and Leaderboards Just Marketing Tools?\n",
      "Dimitri Allaert\n",
      "\"Meet our new LLM, which outperforms GPT in the latest benchmarks!\" Headlines like these are everywhere, especially with the l\n",
      "https://vectrix.ai/career\n",
      "Founded in 2023, Vectrix specializes in training and validating private Small Language Models (SLMs) on business data. We offer DIY and expert-led AI solutions that are accurate, explainable, and secu\n",
      "https://vectrix.ai/platform\n",
      "Introducing Our SLM Platform\n",
      "Small Language Models (SLMs) represent a revolutionary approach in the field of artificial intelligence. These compact powerhouses are designed to deliver specialized, hig\n",
      "https://vectrix.ai/contact-us\n",
      "Ask us your question!\n",
      "We'd love to hear from you! Whether you're curious about our AI-powered solutions, need technical support, or want to discuss how Vectrix can revolutionize your business, fill ou\n",
      "https://vectrix.ai/about-us\n",
      "AI Innovation Studio\n",
      "Meet Team Vectrix\n",
      "Ben Selleslagh\n",
      "Co-Founder\n",
      "Meet Ben, a pivotal player and Co-Founder at Vectrix. With a rich background as a data professional, Ben brings his diverse experience \n",
      "https://vectrix.ai/offerings/chat-ui\n",
      "Vectrix Chat\n",
      "Vectrix Chat is an internal tool that allows you to interact with various Large Language Models (LLMs) and easily switch between them. It also allows you to create your own custom models \n",
      "https://vectrix.ai/offerings/advice\n",
      "Advice\n",
      "Vectrix Advice Services: Collaborative AI Solutions for Your Business\n",
      "AI Consultation and Strategic Advice\n",
      "Vectrix provides expert consultations to help businesses align their AI initiatives wi\n",
      "https://vectrix.ai/offerings/projects\n",
      "Projects\n",
      "Vectrix Projects: Streamlining Business Operations with AI\n",
      "Vectrix is committed to providing AI project solutions that are specifically designed to meet the unique needs of your business. Our\n",
      "https://vectrix.ai/blog-post/the-basics-of-entity-analysis-beyond-just-identifying-names\n",
      "The Basics of Entity Analysis: Beyond Just Identifying Names\n",
      "Dimitri Allaert\n",
      "Introduction\n",
      "Imagine reading a book and highlighting every name, city, or important date. This helps you grasp the story be\n",
      "https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini\n",
      "Image Extraction with Langchain and Gemini\n",
      "Ben Selleslagh\n",
      "In today's digital landscape, businesses are constantly seeking ways to optimize their online presence and streamline their operations. One po\n",
      "https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini\n",
      "Image Extraction with Langchain and Gemini\n",
      "Ben Selleslagh\n",
      "In today's digital landscape, businesses are constantly seeking ways to optimize their online presence and streamline their operations. One po\n",
      "https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini\n",
      "Image Extraction with Langchain and Gemini\n",
      "Ben Selleslagh\n",
      "In today's digital landscape, businesses are constantly seeking ways to optimize their online presence and streamline their operations. One po\n",
      "https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini\n",
      "Image Extraction with Langchain and Gemini\n",
      "Ben Selleslagh\n",
      "In today's digital landscape, businesses are constantly seeking ways to optimize their online presence and streamline their operations. One po\n",
      "https://vectrix.ai/job-list/software-engineer-front-end\n",
      "About Vectrix\n",
      "At Vectrix, we train and validate private Small Language Models (SLMs) on business data, ensuring accuracy, explainability, and security. Based in Antwerp, our flexible platform offers D\n",
      "https://vectrix.ai/job-list/open-application---create-your-own-dream-job\n",
      "About Vectrix\n",
      "At Vectrix, we train and validate private Small Language Models (SLMs) on business data, ensuring accuracy, explainability, and security. Based in Antwerp, our flexible platform offers D\n",
      "https://vectrix.ai/job-list/junior-ai-researcher\n",
      "About Vectrix\n",
      "At Vectrix, we train and validate private Small Language Models (SLMs) on business data, ensuring accuracy, explainability, and security. Based in Antwerp, our flexible platform offers D\n",
      "https://vectrix.ai/job-list/internship\n",
      "About Vectrix\n",
      "At Vectrix, we train and validate private Small Language Models (SLMs) on business data, ensuring accuracy, explainability, and security. Based in Antwerp, our flexible platform offers D\n",
      "https://www.vectrix.ai/offerings\n",
      "Our Offerings\n",
      "Project that challenge force\n",
      "Working with Alex was interesting. He haveing into went beyond what asking provided such an amazing.\n",
      "Project that challenge force\n",
      "Working with Alex was inter\n",
      "https://vectrix.ai\n",
      "What if ...\n",
      "- AI had no security or compliance risks?\n",
      "- You had full control with zero API costs?\n",
      "- AI provided accurate results without hallucinations?\n",
      "- No in-house AI expertise was needed?\n",
      "- AI was\n"
     ]
    }
   ],
   "source": [
    "for page in scraped_pages:\n",
    "    print(page.metadata['url'])\n",
    "    print(page.page_content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectrix import Weaviate\n",
    "\n",
    "weaviate = Weaviate()\n",
    "weaviate.set_colleciton(\"Vectrix\")\n",
    "\n",
    "response = weaviate.list_metadata()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Data to Vector Store using Weaviate\n",
    "\n",
    "This code demonstrates how to add extracted web data to a Weaviate vector store using the Vectrix library.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "1. **Import and Instantiate Weaviate**:\n",
    "   - Import necessary modules from Vectrix\n",
    "   - Create a Weaviate instance\n",
    "\n",
    "2. **Create a Collection**:\n",
    "   - Set up a new collection named 'Vectrix'\n",
    "   - Use a local Ollama model for embeddings\n",
    "   - Specify the model name and URL\n",
    "\n",
    "3. **Prepare Data for Vectorization**:\n",
    "   - Create `VectorDocument` objects for each extracted result\n",
    "   - Include metadata such as title, URL, content, type, and NER information\n",
    "\n",
    "4. **Add Data to Vector Store**:\n",
    "   - Use `weaviate.add_data()` to insert the prepared documents\n",
    "\n",
    "5. **Perform a Test Query**:\n",
    "   - Get a retriever from the Weaviate instance\n",
    "   - Execute a sample query to verify functionality\n",
    "\n",
    "**Note:**\n",
    "- You can remove a collection using `weaviate.remove_collection(\"Vectrix\")`\n",
    "- This example uses a local Ollama model, but you can use any compatible embedding model\n",
    "\n",
    "This code showcases the process of storing and querying vectorized web data using Weaviate and Vectrix, enabling efficient semantic search and retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectrix.db import Weaviate\n",
    "\n",
    "# Instantiation of the Vector store\n",
    "weaviate = Weaviate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectrix.db import Weaviate\n",
    "\n",
    "# Instantiation of the Vector store\n",
    "weaviate = Weaviate()\n",
    "\n",
    "weaviate.remove_collection(\"Vectrix\")\n",
    "\n",
    "# Create a new collection to store the documents (you can also append them to an existsing one)\n",
    "weaviate.create_collection(name='Vectrix', \n",
    "                           embedding_model='Ollama', # For this example we use a local Ollama model, but you can use any other model \n",
    "                           model_name=\"mxbai-embed-large:335m\",\n",
    "                           model_url=\"http://host.docker.internal:11434\") # Ollama Embeddings model URL\n",
    "\n",
    "\n",
    "weaviate.add_data(chunked_webdata)\n",
    "\n",
    "\n",
    "# Perform a quick search to see if it works\n",
    "retriever = weaviate.get_retriever()\n",
    "retriever.invoke('Who are the Vectrix founders ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.set_colleciton('Vectrix')\n",
    "retriever = weaviate.get_retriever()\n",
    "retriever.invoke('Who are the Vectrix founders ?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From OneDrive ‚òÅ\n",
    "We can also connect with a OneDrive folder and download the information from there. After this process we can add the information to our Vector store in the same way. This way we can extract various kinds of documents like PDF, World, PowerPoint ...\n",
    "\n",
    "Downloads files from OneDrive, processes them with Unstructured, and stores in Weaviate.\n",
    "\n",
    "Steps:\n",
    "1. Connect to OneDrive using Azure credentials\n",
    "2. List and download all files\n",
    "3. Process files with Unstructured importer\n",
    "4. Add processed documents to Weaviate vector store\n",
    "5. Close OneDrive connection\n",
    "\n",
    "Requirements:\n",
    "- vectrix library (OneDrive connector, Unstructured importer)\n",
    "- Weaviate client\n",
    "- Azure credentials as environment variables (AZURE_CLIENT_ID, AZURE_CLIENT_SECRET)\n",
    "\n",
    "Note: Close OneDrive connection before uploading to vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectrix.connectors.onedrive import OneDrive\n",
    "from vectrix.importers.unstructured import Unstructured\n",
    "\n",
    "drive = OneDrive(azure_client_id = os.environ.get('AZURE_CLIENT_ID'), azure_client_secret = os.environ.get('AZURE_CLIENT_SECRET'))\n",
    "\n",
    "drive.list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all files in the drive, returns a list of downloaded files\n",
    "downloaded_files = drive.download_files()\n",
    "print(downloaded_files)\n",
    "\n",
    "# Process teh documents using unstructured (we can't load RAW PDF files into a Vector store)\n",
    "importer = Unstructured()\n",
    "documents = importer.process_files(downloaded_files)\n",
    "\n",
    "# Add the documents to the Vector store\n",
    "weaviate = Weaviate()\n",
    "weaviate.set_colleciton('Vectrix')\n",
    "weaviate.add_data(documents)\n",
    "\n",
    "# Close the drive, do this BEFORE you want to upload the files to a vector store\n",
    "drive.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
