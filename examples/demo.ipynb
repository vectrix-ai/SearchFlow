{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", ResourceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectrix Demo üë®üèª‚Äçüíª\n",
    "This notebook demonstrates the functions for importing data from various sources. \n",
    "Loading it into a VectorStore, and then using it to answer questions with a Retrieval Augemented Reasoning  ü¶úüîó LangGraph.\n",
    "\n",
    "## Importing Data\n",
    "### 1. From a URL üîó\n",
    "\n",
    "**Web Crawling and Data Extraction Example**\n",
    "\n",
    "This cell demonstrates the process of crawling a website, chunking the extracted content, and performing Named Entity Recognition (NER) using the Vectrix library.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. **Web Crawling**: \n",
    "   - Uses `vectrix.Crawler` to extract pages from \"https://vectrix.ai\"\n",
    "   - Limits the crawl to a maximum of 20 pages\n",
    "\n",
    "2. **Content Chunking**:\n",
    "   - Utilizes `vectrix.Webchunker` to break down the extracted content\n",
    "   - Chunks are created with a size of 500 characters and an overlap of 50 characters\n",
    "\n",
    "3. **Named Entity Recognition**:\n",
    "   - Employs `vectrix.Extract` with the 'Replicate' model\n",
    "   - Uses the 'meta/meta-llama-3-70b-instruct' model for entity extraction\n",
    "\n",
    "This example showcases a typical workflow for web data extraction and processing using the Vectrix library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2024-08-14 23:59:51,671 - trafilatura.downloads - ERROR - not a 200 response: 404 for URL https://www.vectrix.ai/robots.txt\u001b[0m\n",
      "\u001b[31m2024-08-14 23:59:51,671 - trafilatura.downloads - ERROR - not a 200 response: 404 for URL https://www.vectrix.ai/robots.txt\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:51,733 - courlan.core - INFO - 14 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:51,733 - courlan.core - INFO - 14 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:51,734 - root - INFO - Starting to scrape 11 links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:51,734 - root - INFO - Starting to scrape 11 links\u001b[0m\n",
      "\u001b[31m2024-08-14 23:59:51,914 - trafilatura.downloads - ERROR - not a 200 response: 404 for URL https://www.vectrix.ai/robots.txt\u001b[0m\n",
      "\u001b[31m2024-08-14 23:59:51,914 - trafilatura.downloads - ERROR - not a 200 response: 404 for URL https://www.vectrix.ai/robots.txt\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:51,973 - courlan.urlstore - WARNING - Discarding URL: /platform\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:51,973 - courlan.urlstore - WARNING - Discarding URL: /platform\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:51,974 - courlan.core - INFO - 10 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:51,974 - courlan.core - INFO - 10 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:53,047 - courlan.urlstore - WARNING - Discarding URL: /career\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:53,047 - courlan.urlstore - WARNING - Discarding URL: /career\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:53,049 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:53,049 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:54,106 - courlan.urlstore - WARNING - Discarding URL: /blog-post/your-ai-might-be-misleading-you-understanding-the-dual-nature-of-llm-outputs\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:54,106 - courlan.urlstore - WARNING - Discarding URL: /blog-post/your-ai-might-be-misleading-you-understanding-the-dual-nature-of-llm-outputs\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:54,108 - courlan.core - INFO - 16 links found ‚Äì 12 valid links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:54,108 - courlan.core - INFO - 16 links found ‚Äì 12 valid links\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:55,177 - courlan.urlstore - WARNING - Discarding URL: /about-us\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:55,177 - courlan.urlstore - WARNING - Discarding URL: /about-us\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:55,179 - courlan.core - INFO - 13 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:55,179 - courlan.core - INFO - 13 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:56,247 - courlan.urlstore - WARNING - Discarding URL: /contact-us\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:56,247 - courlan.urlstore - WARNING - Discarding URL: /contact-us\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:56,248 - courlan.core - INFO - 10 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:56,248 - courlan.core - INFO - 10 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:57,317 - courlan.urlstore - WARNING - Discarding URL: /blog-post/understanding-large-and-small-language-models-key-differences-and-applications\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:57,317 - courlan.urlstore - WARNING - Discarding URL: /blog-post/understanding-large-and-small-language-models-key-differences-and-applications\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:57,318 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:57,318 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:58,392 - courlan.urlstore - WARNING - Discarding URL: /blog\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:58,392 - courlan.urlstore - WARNING - Discarding URL: /blog\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:58,394 - courlan.core - INFO - 17 links found ‚Äì 14 valid links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:58,394 - courlan.core - INFO - 17 links found ‚Äì 14 valid links\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:59,459 - courlan.urlstore - WARNING - Discarding URL: /offerings\u001b[0m\n",
      "\u001b[33m2024-08-14 23:59:59,459 - courlan.urlstore - WARNING - Discarding URL: /offerings\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:59,461 - courlan.core - INFO - 13 links found ‚Äì 10 valid links\u001b[0m\n",
      "\u001b[32m2024-08-14 23:59:59,461 - courlan.core - INFO - 13 links found ‚Äì 10 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:00,532 - courlan.urlstore - WARNING - Discarding URL: /blog-post/google-deepminds-searchless-chess-engine---part-1\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:00,532 - courlan.urlstore - WARNING - Discarding URL: /blog-post/google-deepminds-searchless-chess-engine---part-1\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:00,534 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:00,534 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:01,604 - courlan.urlstore - WARNING - Discarding URL: /blog-post/are-llm-benchmarks-and-leaderboards-just-marketing-tools\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:01,604 - courlan.urlstore - WARNING - Discarding URL: /blog-post/are-llm-benchmarks-and-leaderboards-just-marketing-tools\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:01,605 - courlan.core - INFO - 16 links found ‚Äì 12 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:01,605 - courlan.core - INFO - 16 links found ‚Äì 12 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:02,672 - courlan.urlstore - WARNING - Discarding URL: /job-list/open-application---create-your-own-dream-job\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:02,672 - courlan.urlstore - WARNING - Discarding URL: /job-list/open-application---create-your-own-dream-job\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:02,673 - courlan.core - INFO - 13 links found ‚Äì 10 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:02,673 - courlan.core - INFO - 13 links found ‚Äì 10 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:03,738 - courlan.urlstore - WARNING - Discarding URL: /job-list/software-engineer-front-end\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:03,738 - courlan.urlstore - WARNING - Discarding URL: /job-list/software-engineer-front-end\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:03,739 - courlan.core - INFO - 13 links found ‚Äì 10 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:03,739 - courlan.core - INFO - 13 links found ‚Äì 10 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:04,801 - courlan.urlstore - WARNING - Discarding URL: /job-list/junior-ai-researcher\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:04,801 - courlan.urlstore - WARNING - Discarding URL: /job-list/junior-ai-researcher\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:04,803 - courlan.core - INFO - 13 links found ‚Äì 10 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:04,803 - courlan.core - INFO - 13 links found ‚Äì 10 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:05,872 - courlan.urlstore - WARNING - Discarding URL: /job-list/internship\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:05,872 - courlan.urlstore - WARNING - Discarding URL: /job-list/internship\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:05,874 - courlan.core - INFO - 13 links found ‚Äì 10 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:05,874 - courlan.core - INFO - 13 links found ‚Äì 10 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:06,948 - courlan.urlstore - WARNING - Discarding URL: /blog-post/advanced-applications-and-future-trends-in-entity-analysis\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:06,948 - courlan.urlstore - WARNING - Discarding URL: /blog-post/advanced-applications-and-future-trends-in-entity-analysis\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:06,950 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:06,950 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:08,020 - courlan.urlstore - WARNING - Discarding URL: /blog-post/the-basics-of-entity-analysis-beyond-just-identifying-names\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:08,020 - courlan.urlstore - WARNING - Discarding URL: /blog-post/the-basics-of-entity-analysis-beyond-just-identifying-names\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:08,022 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:08,022 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:09,101 - courlan.urlstore - WARNING - Discarding URL: /blog-post/image-extraction-with-langchain-and-gemini\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:09,101 - courlan.urlstore - WARNING - Discarding URL: /blog-post/image-extraction-with-langchain-and-gemini\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:09,102 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:09,102 - courlan.core - INFO - 15 links found ‚Äì 11 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:10,157 - courlan.urlstore - WARNING - Discarding URL: /offerings/projects\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:10,157 - courlan.urlstore - WARNING - Discarding URL: /offerings/projects\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:10,158 - courlan.core - INFO - 10 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:10,158 - courlan.core - INFO - 10 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:11,225 - courlan.urlstore - WARNING - Discarding URL: /offerings/chat-ui\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:11,225 - courlan.urlstore - WARNING - Discarding URL: /offerings/chat-ui\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:11,227 - courlan.core - INFO - 11 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:11,227 - courlan.core - INFO - 11 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:12,304 - courlan.urlstore - WARNING - Discarding URL: /offerings/advice\u001b[0m\n",
      "\u001b[33m2024-08-15 00:00:12,304 - courlan.urlstore - WARNING - Discarding URL: /offerings/advice\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:12,305 - courlan.core - INFO - 10 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:12,305 - courlan.core - INFO - 10 links found ‚Äì 7 valid links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:13,312 - root - INFO - Finished scraping 21 links\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:13,312 - root - INFO - Finished scraping 21 links\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from vectrix.importers import WebScraper\n",
    "\n",
    "scraper = WebScraper(\"https://www.vectrix.ai/\")\n",
    "all_links = scraper.get_all_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-15 00:00:13,326 - root - INFO - Listing all pages for domain: www.vectrix.ai\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:13,326 - root - INFO - Listing all pages for domain: www.vectrix.ai\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:13,478 - root - INFO - Getting all documents for domain: www.vectrix.ai\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:13,478 - root - INFO - Getting all documents for domain: www.vectrix.ai\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_pages = scraper.get_all_pages(all_links)\n",
    "len(web_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before chunking we had 21 and after chunking 21\n"
     ]
    }
   ],
   "source": [
    "from vectrix.importers import chunk_content\n",
    "chunked_webpages = chunk_content(web_pages)\n",
    "\n",
    "\n",
    "print(f\"Before chunking we had {len(web_pages)} and after chunking {len(chunked_webpages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Data to Vector Store using Weaviate\n",
    "\n",
    "This code demonstrates how to add extracted web data to a Weaviate vector store using the Vectrix library.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "1. **Import and Instantiate Weaviate**:\n",
    "   - Import necessary modules from Vectrix\n",
    "   - Create a Weaviate instance\n",
    "\n",
    "2. **Create a Collection**:\n",
    "   - Set up a new collection named 'Vectrix'\n",
    "   - Use a local Ollama model for embeddings\n",
    "   - Specify the model name and URL\n",
    "\n",
    "3. **Prepare Data for Vectorization**:\n",
    "   - Create `VectorDocument` objects for each extracted result\n",
    "   - Include metadata such as title, URL, content, type, and NER information\n",
    "\n",
    "4. **Add Data to Vector Store**:\n",
    "   - Use `weaviate.add_data()` to insert the prepared documents\n",
    "\n",
    "5. **Perform a Test Query**:\n",
    "   - Get a retriever from the Weaviate instance\n",
    "   - Execute a sample query to verify functionality\n",
    "\n",
    "**Note:**\n",
    "- You can remove a collection using `weaviate.remove_collection(\"Vectrix\")`\n",
    "- This example uses a local Ollama model, but you can use any compatible embedding model\n",
    "\n",
    "This code showcases the process of storing and querying vectorized web data using Weaviate and Vectrix, enabling efficient semantic search and retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-15 00:00:18,955 - httpx - INFO - HTTP Request: GET https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/meta \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:18,955 - httpx - INFO - HTTP Request: GET https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/meta \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:19,041 - httpx - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:19,041 - httpx - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723672819.082231 1311905 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
     ]
    }
   ],
   "source": [
    "from vectrix.db import Weaviate\n",
    "\n",
    "# Instantiation of the Vector store\n",
    "weaviate = Weaviate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-15 00:00:22,256 - httpx - INFO - HTTP Request: GET https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/meta \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:22,256 - httpx - INFO - HTTP Request: GET https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/meta \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:22,348 - httpx - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:22,348 - httpx - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:22,769 - httpx - INFO - HTTP Request: DELETE https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/schema/Vectrix \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:22,769 - httpx - INFO - HTTP Request: DELETE https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/schema/Vectrix \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:22,978 - httpx - INFO - HTTP Request: POST https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/schema \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:22,978 - httpx - INFO - HTTP Request: POST https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/schema \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:23,024 - httpx - INFO - HTTP Request: GET https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/schema/Vectrix \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:23,024 - httpx - INFO - HTTP Request: GET https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/schema/Vectrix \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:23,081 - httpx - INFO - HTTP Request: GET https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/nodes \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32m2024-08-15 00:00:23,081 - httpx - INFO - HTTP Request: GET https://esus6owcs6iz4lv8rw5vta.c0.europe-west3.gcp.weaviate.cloud/v1/nodes \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Vectrix - About Us', 'url': 'https://www.vectrix.ai/about-us', 'source_type': 'webpage', 'source_format': 'html', 'uuid': 'a843f8ea-a46c-4de0-99e5-c9f21778754d', 'score': 0.710525393486023}, page_content=\"AI Innovation Studio Meet Team Vectrix Ben Selleslagh Co-Founder Meet Ben, a pivotal player and Co-Founder at Vectrix. With a rich background as a data professional, Ben brings his diverse experience from banking, government, and media sectors into the mix. He's skilled in crafting and executing data-driven strategies that sync perfectly with business goals. His expertise in Google Cloud technology makes him a wizard at building scalable and efficient data architectures. At Vectrix, Ben applies his know-how to innovate and drive our data and AI solutions, always with an eye on efficiency and scalability, ensuring that we stay at the forefront of AI technology. Dimitri Allaert Co-Founder Meet Dimitri Allaert, a driving force and Co-Founder at Vectrix. With roots in medical engineering and a history in the pharmaceutical world, Dimitri brings a different twist to our AI solutions. He kicked off his journey co-founding BUFFL, a market research platform, and then moved on in 2021 to dive into AI and emerging tech. At Vectrix, he's all about smart strategies and putting customers first, helping steer us towards exciting new developments in AI.\"),\n",
       " Document(metadata={'title': 'Job Description', 'url': 'https://www.vectrix.ai/job-list/open-application---create-your-own-dream-job', 'source_type': 'webpage', 'source_format': 'html', 'uuid': 'be4226ed-2a39-4d2f-adf0-910ed7c98859', 'score': 0.6728050708770752}, page_content=\"About Vectrix At Vectrix, we train and validate private Small Language Models (SLMs) on business data, ensuring accuracy, explainability, and security. Based in Antwerp, our flexible platform offers DIY tools and expert collaboration, leveraging Retrieval Augmented Reasoning (RAR) for precise, contextually relevant answers. Join our innovative team and shape your career in a dynamic environment. At Vectrix, you‚Äôll make a real impact and grow your skills in a supportive setting. Ready to advance AI with us? Apply now! \\u200d Position Overview We are growing rapidly and our hiring plans are expanding just as quickly. We are looking for highly motivated team members who want to help build one of the leading companies in AI. If you're passionate about AI and haven't seen a role on our job board that matches your career aspirations, we still want to hear from you! Feel free to submit an open application and create your dream job at Vectrix. \\u200d What We Offer A stimulating work environment in the heart of Antwerp. The opportunity to be part of a pioneering team in AI. Access to state-of-the-art technology and resources. A platform to grow your skills and career in the AI domain. Competitive salary and benefits.\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vectrix.db import Weaviate\n",
    "\n",
    "# Instantiation of the Vector store\n",
    "weaviate = Weaviate()\n",
    "\n",
    "weaviate.remove_collection(\"Vectrix\")\n",
    "\n",
    "# Create a new collection to store the documents (you can also append them to an existsing one)\n",
    "weaviate.create_collection(name='Vectrix', \n",
    "                           embedding_model='Cohere')\n",
    "\n",
    "\n",
    "weaviate.add_data(chunked_webpages)\n",
    "\n",
    "\n",
    "# Perform a quick search to see if it works\n",
    "retriever = weaviate.get_retriever()\n",
    "retriever.invoke('Who are the Vectrix founders ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate.set_colleciton('Vectrix')\n",
    "retriever = weaviate.get_retriever()\n",
    "retriever.invoke('Who are the Vectrix founders ?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From OneDrive ‚òÅ\n",
    "We can also connect with a OneDrive folder and download the information from there. After this process we can add the information to our Vector store in the same way. This way we can extract various kinds of documents like PDF, World, PowerPoint ...\n",
    "\n",
    "Downloads files from OneDrive, processes them with Unstructured, and stores in Weaviate.\n",
    "\n",
    "Steps:\n",
    "1. Connect to OneDrive using Azure credentials\n",
    "2. List and download all files\n",
    "3. Process files with Unstructured importer\n",
    "4. Add processed documents to Weaviate vector store\n",
    "5. Close OneDrive connection\n",
    "\n",
    "Requirements:\n",
    "- vectrix library (OneDrive connector, Unstructured importer)\n",
    "- Weaviate client\n",
    "- Azure credentials as environment variables (AZURE_CLIENT_ID, AZURE_CLIENT_SECRET)\n",
    "\n",
    "Note: Close OneDrive connection before uploading to vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectrix.connectors.onedrive import OneDrive\n",
    "from vectrix.importers.unstructured import Unstructured\n",
    "\n",
    "drive = OneDrive(azure_client_id = os.environ.get('AZURE_CLIENT_ID'), azure_client_secret = os.environ.get('AZURE_CLIENT_SECRET'))\n",
    "\n",
    "drive.list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all files in the drive, returns a list of downloaded files\n",
    "downloaded_files = drive.download_files()\n",
    "print(downloaded_files)\n",
    "\n",
    "# Process teh documents using unstructured (we can't load RAW PDF files into a Vector store)\n",
    "importer = Unstructured()\n",
    "documents = importer.process_files(downloaded_files)\n",
    "\n",
    "# Add the documents to the Vector store\n",
    "weaviate = Weaviate()\n",
    "weaviate.set_colleciton('Vectrix')\n",
    "weaviate.add_data(documents)\n",
    "\n",
    "# Close the drive, do this BEFORE you want to upload the files to a vector store\n",
    "drive.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
