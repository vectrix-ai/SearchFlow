{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", ResourceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectrix Demo üë®üèª‚Äçüíª\n",
    "This notebook demonstrates the functions for importing data from various sources. \n",
    "Loading it into a VectorStore, and then using it to answer questions with a Retrieval Augemented Reasoning  ü¶úüîó LangGraph.\n",
    "\n",
    "## Importing Data\n",
    "### 1. From a URL üîó\n",
    "\n",
    "**Web Crawling and Data Extraction Example**\n",
    "\n",
    "This cell demonstrates the process of crawling a website, chunking the extracted content, and performing Named Entity Recognition (NER) using the Vectrix library.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. **Web Crawling**: \n",
    "   - Uses `vectrix.Crawler` to extract pages from \"https://vectrix.ai\"\n",
    "   - Limits the crawl to a maximum of 20 pages\n",
    "\n",
    "2. **Content Chunking**:\n",
    "   - Utilizes `vectrix.Webchunker` to break down the extracted content\n",
    "   - Chunks are created with a size of 500 characters and an overlap of 50 characters\n",
    "\n",
    "3. **Named Entity Recognition**:\n",
    "   - Employs `vectrix.Extract` with the 'Replicate' model\n",
    "   - Uses the 'meta/meta-llama-3-70b-instruct' model for entity extraction\n",
    "\n",
    "This example showcases a typical workflow for web data extraction and processing using the Vectrix library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "INFO:vectrix.importers.webscraper:Starting extraction pipeline for site: vectrix.ai\n",
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  2.76it/s]\n",
      "/Users/ben/GitHub/vectrix/.venv/lib/python3.12/site-packages/bs4/builder/__init__.py:314: ResourceWarning: unclosed <socket.socket fd=83, family=2, type=1, proto=6, laddr=('10.52.13.79', 53133), raddr=('75.2.70.75', 443)>\n",
      "  for attr in list(attrs.keys()):\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=83>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/ben/GitHub/vectrix/.venv/lib/python3.12/site-packages/bs4/builder/__init__.py:314: ResourceWarning: unclosed <socket.socket fd=84, family=2, type=1, proto=6, laddr=('10.52.13.79', 53134), raddr=('52.17.119.105', 443)>\n",
      "  for attr in list(attrs.keys()):\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=84>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "INFO:vectrix.importers.webscraper:Visiting the following links: ['https://vectrix.ai/blog-post/advanced-applications-and-future-trends-in-entity-analysis', 'https://vectrix.ai/blog-post/are-llm-benchmarks-and-leaderboards-just-marketing-tools', 'https://vectrix.ai/career', 'https://vectrix.ai/offerings', 'https://vectrix.ai/blog-post/understanding-large-and-small-language-models-key-differences-and-applications', 'https://vectrix.ai/platform', 'https://vectrix.ai/blog', 'https://vectrix.ai/contact-us', 'https://vectrix.ai/about-us', 'https://vectrix.ai/blog-post/google-deepminds-searchless-chess-engine---part-1']\n",
      "Fetching pages: 100%|##########| 10/10 [00:01<00:00,  5.70it/s]\n",
      "/Users/ben/GitHub/vectrix/.venv/lib/python3.12/site-packages/bs4/builder/__init__.py:311: ResourceWarning: unclosed <socket.socket fd=85, family=2, type=1, proto=6, laddr=('10.52.13.79', 53152), raddr=('75.2.70.75', 443)>\n",
      "  universal = self.cdata_list_attributes.get('*', [])\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=85>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/ben/GitHub/vectrix/.venv/lib/python3.12/site-packages/bs4/builder/__init__.py:311: ResourceWarning: unclosed <socket.socket fd=87, family=2, type=1, proto=6, laddr=('10.52.13.79', 53154), raddr=('34.249.200.254', 443)>\n",
      "  universal = self.cdata_list_attributes.get('*', [])\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=87>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "INFO:vectrix.importers.webscraper:Number of pages processed: 10\n",
      "INFO:vectrix.importers.webscraper:Number of links to visit: 13\n",
      "INFO:vectrix.importers.webscraper:Visiting the following links: ['https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/job-list/junior-ai-researcher', 'https://vectrix.ai/job-list/internship', 'https://vectrix.ai/job-list/software-engineer-front-end', 'https://vectrix.ai/job-list/open-application---create-your-own-dream-job', 'https://vectrix.ai/offerings/chat-ui', 'https://vectrix.ai/offerings/projects', 'https://vectrix.ai/offerings/advice', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/blog-post/image-extraction-with-langchain-and-gemini', 'https://vectrix.ai/blog-post/the-basics-of-entity-analysis-beyond-just-identifying-names', 'https://www.vectrix.ai/offerings']\n",
      "Fetching pages: 100%|##########| 13/13 [00:02<00:00,  5.96it/s]\n",
      "/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/html/parser.py:386: ResourceWarning: unclosed <socket.socket fd=90, family=2, type=1, proto=6, laddr=('10.52.13.79', 53179), raddr=('34.249.200.254', 443)>\n",
      "  match = endtagfind.match(rawdata, i) # </ + tag + >\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=90>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "INFO:vectrix.importers.webscraper:Number of pages processed: 23\n",
      "INFO:vectrix.importers.webscraper:Number of links to visit: 0\n",
      "INFO:vectrix.importers.webscraper:Download finished. Extracting content from the pages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 24 pages\n",
      "Example CHUNK: \n",
      "page_content='can unlock new insights and make smarter decisions, enhancing our lives and business practices. What You Will Learn When Reading the Full Blog Post In the full blog post, you'll explore how entity analysis revolutionizes healthcare, finance, and legal services by extracting meaningful insights from data. You'll learn about real-world applications and the technical implementations driving these innovations. Additionally, discover future trends like real-time processing, multimodal analysis, and the integration of generative AI that promise to enhance personalization and decision-making in various fields. Whether you're looking for a technical deep dive or practical examples, the full post offers a comprehensive understanding of the potential and future of entity analysis.' metadata={'url': 'https://vectrix.ai/blog-post/advanced-applications-and-future-trends-in-entity-analysis', 'title': 'Advanced Applications & Future Trends in Entity Analysis', 'description': 'Discover how entity analysis is transforming healthcare, finance, and legal services. Learn about advanced applications, real-world examples, and future trends like real-time processing and generative AI. Read more now!', 'language': 'en', 'extraction_ts': '2024-08-05 18:07:20', 'source_type': 'webscrape', 'source_format': 'HTML'}\n"
     ]
    }
   ],
   "source": [
    "# Extracting data from a URL\n",
    "from vectrix.importers import WebCrawler, ChunkData\n",
    "\n",
    "crawler =  WebCrawler(\"https://vectrix.ai\")\n",
    "extracted_pages = crawler.extract()\n",
    "\n",
    "print(f\"Extracted {len(extracted_pages)} pages\")\n",
    "\n",
    "# Chunk the data\n",
    "\n",
    "chunked_webdata = ChunkData.chunk_content(extracted_pages, chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "print(\"Example CHUNK: \")\n",
    "print(chunked_webdata[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Data to Vector Store using Weaviate\n",
    "\n",
    "This code demonstrates how to add extracted web data to a Weaviate vector store using the Vectrix library.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "1. **Import and Instantiate Weaviate**:\n",
    "   - Import necessary modules from Vectrix\n",
    "   - Create a Weaviate instance\n",
    "\n",
    "2. **Create a Collection**:\n",
    "   - Set up a new collection named 'Vectrix'\n",
    "   - Use a local Ollama model for embeddings\n",
    "   - Specify the model name and URL\n",
    "\n",
    "3. **Prepare Data for Vectorization**:\n",
    "   - Create `VectorDocument` objects for each extracted result\n",
    "   - Include metadata such as title, URL, content, type, and NER information\n",
    "\n",
    "4. **Add Data to Vector Store**:\n",
    "   - Use `weaviate.add_data()` to insert the prepared documents\n",
    "\n",
    "5. **Perform a Test Query**:\n",
    "   - Get a retriever from the Weaviate instance\n",
    "   - Execute a sample query to verify functionality\n",
    "\n",
    "**Note:**\n",
    "- You can remove a collection using `weaviate.remove_collection(\"Vectrix\")`\n",
    "- This example uses a local Ollama model, but you can use any compatible embedding model\n",
    "\n",
    "This code showcases the process of storing and querying vectorized web data using Weaviate and Vectrix, enabling efficient semantic search and retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/.well-known/openid-configuration \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/meta \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: DELETE http://localhost:8080/v1/schema/Vectrix \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8080/v1/schema \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/schema/Vectrix \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/nodes \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/nodes \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/nodes \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Open Application - Create Your Dream Job at Vectrix', 'url': 'https://vectrix.ai/job-list/open-application---create-your-own-dream-job', 'source_type': 'webscrape', 'source_format': 'HTML', 'uuid': '4077aa78-f8a3-4efa-8457-96da23033ca4', 'score': 0.9064530730247498}, page_content=\"About Vectrix At Vectrix, we train and validate private Small Language Models (SLMs) on business data, ensuring accuracy, explainability, and security. Based in Antwerp, our flexible platform offers DIY tools and expert collaboration, leveraging Retrieval Augmented Reasoning (RAR) for precise, contextually relevant answers. Join our innovative team and shape your career in a dynamic environment. At Vectrix, you‚Äôll make a real impact and grow your skills in a supportive setting. Ready to advance AI with us? Apply now! Position Overview We are growing rapidly and our hiring plans are expanding just as quickly. We are looking for highly motivated team members who want to help build one of the leading companies in AI. If you're passionate about AI and haven't seen a role on our job board that matches your career aspirations, we still want to hear from you! Feel free to submit an open application and create your dream job at Vectrix. What We Offer - A stimulating work environment in the heart of Antwerp. - The opportunity to be part of a pioneering team in AI. - Access to state-of-the-art technology and resources. - A platform to grow your skills and career in the AI domain. - Competitive salary and benefits.\"),\n",
       " Document(metadata={'title': 'Junior AI Researcher Position at Vectrix', 'url': 'https://vectrix.ai/job-list/junior-ai-researcher', 'source_type': 'webscrape', 'source_format': 'HTML', 'uuid': 'a2404d17-8f53-4ddb-b421-e4610f6570b5', 'score': 0.7687416076660156}, page_content='About Vectrix At Vectrix, we train and validate private Small Language Models (SLMs) on business data, ensuring accuracy, explainability, and security. Based in Antwerp, our flexible platform offers DIY tools and expert collaboration, leveraging Retrieval Augmented Reasoning (RAR) for precise, contextually relevant answers. Join our innovative team and shape your career in a dynamic environment. At Vectrix, you‚Äôll make a real impact and grow your skills in a supportive setting. Ready to advance AI with us? Apply now! Position Overview We are currently seeking a passionate and skilled Junior AI Researcher to join our dynamic team. This role is ideal for someone who is deeply intrigued by the world of AI and eager to contribute to the development and deployment of groundbreaking AI technologies. Key Responsibilities - Collaborate with a team of experts to develop and refine generative AI models. - Implement AI solutions using Python, focusing on robustness and scalability. - Engage in the deployment of AI systems, ensuring smooth integration and functionality. - Work with Google Cloud platforms to leverage cloud computing resources effectively. - Contribute to research initiatives and stay updated with the latest trends in AI. Qualifications - Bachelor‚Äôs or Master‚Äôs degree in Computer Science, Artificial Intelligence, or a related field. - Proficiency in Python programming, with a strong grasp of AI-related libraries and frameworks. - Experience in deploying AI solutions, with a focus on practical and real-world applications. - Hands-on experience with Google Cloud platforms is highly desirable. - Excellent problem-solving skills and a keen interest in AI research and development. - Ability to work collaboratively in a team and communicate effectively. What We Offer - A stimulating work environment in the heart of Antwerp. - The opportunity to be part of a pioneering team in AI. - Access to state-of-the-art technology and resources. - A platform to grow your skills and career in the AI domain. - Competitive salary and benefits.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vectrix.db import Weaviate\n",
    "from vectrix.models import VectorDocument\n",
    "\n",
    "# Instantiation of the Vector store\n",
    "weaviate = Weaviate()\n",
    "\n",
    "weaviate.remove_collection(\"Vectrix\")\n",
    "\n",
    "# Create a new collection to store the documents (you can also append them to an existsing one)\n",
    "weaviate.create_collection(name='Vectrix', \n",
    "                           embedding_model='Ollama', # For this example we use a local Ollama model, but you can use any other model \n",
    "                           model_name=\"mxbai-embed-large:335m\",\n",
    "                           model_url=\"http://host.docker.internal:11434\") # Ollama Embeddings model URL\n",
    "\n",
    "\n",
    "weaviate.add_data(chunked_webdata)\n",
    "\n",
    "\n",
    "# Perform a quick search to see if it works\n",
    "retriever = weaviate.get_retriever()\n",
    "retriever.invoke('Who are the Vectrix founders ?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From OneDrive ‚òÅ\n",
    "We can also connect with a OneDrive folder and download the information from there. After this process we can add the information to our Vector store in the same way. This way we can extract various kinds of documents like PDF, World, PowerPoint ...\n",
    "\n",
    "Downloads files from OneDrive, processes them with Unstructured, and stores in Weaviate.\n",
    "\n",
    "Steps:\n",
    "1. Connect to OneDrive using Azure credentials\n",
    "2. List and download all files\n",
    "3. Process files with Unstructured importer\n",
    "4. Add processed documents to Weaviate vector store\n",
    "5. Close OneDrive connection\n",
    "\n",
    "Requirements:\n",
    "- vectrix library (OneDrive connector, Unstructured importer)\n",
    "- Weaviate client\n",
    "- Azure credentials as environment variables (AZURE_CLIENT_ID, AZURE_CLIENT_SECRET)\n",
    "\n",
    "Note: Close OneDrive connection before uploading to vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectrix.connectors.onedrive import OneDrive\n",
    "from vectrix.importers.unstructured import Unstructured\n",
    "\n",
    "drive = OneDrive(azure_client_id = os.environ.get('AZURE_CLIENT_ID'), azure_client_secret = os.environ.get('AZURE_CLIENT_SECRET'))\n",
    "\n",
    "drive.list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all files in the drive, returns a list of downloaded files\n",
    "downloaded_files = drive.download_files()\n",
    "print(downloaded_files)\n",
    "\n",
    "# Process teh documents using unstructured (we can't load RAW PDF files into a Vector store)\n",
    "importer = Unstructured()\n",
    "documents = importer.process_files(downloaded_files)\n",
    "\n",
    "# Add the documents to the Vector store\n",
    "weaviate = Weaviate()\n",
    "weaviate.set_colleciton('Vectrix')\n",
    "weaviate.add_data(documents)\n",
    "\n",
    "# Close the drive, do this BEFORE you want to upload the files to a vector store\n",
    "drive.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
