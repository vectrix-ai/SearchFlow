{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup ðŸ“”\n",
    "This notebook will explain how to setup all required depedencies to run Vectrix. For some components you can use paid or hosted services, but for the sake of this setup we will focuse on open source solutions.\n",
    "\n",
    "## Weaviate Vector Database\n",
    "This is needed to store the embeddings and run the vector search. It's important to use a multi-modal embeddings engine since extracted documents can also contain images and graphs you might want to search on.\n",
    "\n",
    "**The Docker Compose File**\n",
    "```yaml\n",
    "---\n",
    "services:\n",
    "  weaviate:\n",
    "    command:\n",
    "    - --host\n",
    "    - 0.0.0.0\n",
    "    - --port\n",
    "    - '8080'\n",
    "    - --scheme\n",
    "    - http\n",
    "    image: cr.weaviate.io/semitechnologies/weaviate:1.26.0\n",
    "    ports:\n",
    "    - 8080:8080\n",
    "    - 50051:50051\n",
    "    volumes:\n",
    "    - ~/weaviate_data:/var/lib/weaviate\n",
    "    restart: on-failure:0\n",
    "    environment:\n",
    "      SPELLCHECK_INFERENCE_API: 'http://text-spellcheck:8080'\n",
    "      QUERY_DEFAULTS_LIMIT: 25\n",
    "      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n",
    "      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n",
    "      DEFAULT_VECTORIZER_MODULE: 'text2vec-ollama'\n",
    "      ENABLE_MODULES: 'text2vec-ollama,text-spellcheck,generative-ollama'\n",
    "      CLUSTER_HOSTNAME: 'node1'\n",
    "  text-spellcheck:\n",
    "    image: cr.weaviate.io/semitechnologies/text-spellcheck-model:pyspellchecker-en\n",
    "volumes:\n",
    "  weaviate_data:\n",
    "...\n",
    "```\n",
    "\n",
    "Note that we did not include an Ollama service since we will use the locally installed version of Ollama for this setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First download an embeddings model using ollama\n",
    "!ollama pull mxbai-embed-large:335m\n",
    "\n",
    "# Download the docker-compose file for Weaviate\n",
    "!docker compose --project-name weaviate up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Docker container from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                    docker:desktop-linux\n",
      " => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.0s (1/1) FINISHED                           docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2B                                         0.0s\n",
      "\u001b[0m\u001b[?25hERROR: failed to solve: failed to read dockerfile: open Dockerfile: no such file or directory\n",
      "\n",
      "View build details: \u001b]8;;docker-desktop://dashboard/build/desktop-linux/desktop-linux/wl7rww0bdozoq2qyfkv6nuepj\u001b\\docker-desktop://dashboard/build/desktop-linux/desktop-linux/wl7rww0bdozoq2qyfkv6nuepj\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "!docker build --no-cache -t vectrix ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### Run the container and attach the enviroment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -p 8501:8501 --env-file .env vectrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the PostgreSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the postgres image, install the pgvector extension and run the container\n",
    "!docker pull ankane/pgvector\n",
    "!docker run -d --name paginx -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 -e PG_EXTENSIONS=\"pgvector\" ankane/pgvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "from google.cloud.sql.connector import Connector, IPTypes\n",
    "import pg8000\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "\n",
    "def connect_with_connector() -> sqlalchemy.engine.base.Engine:\n",
    "    \"\"\"\n",
    "    Initializes a connection pool for a Cloud SQL instance of Postgres.\n",
    "\n",
    "    Uses the Cloud SQL Python Connector package.\n",
    "    \"\"\"\n",
    "    # Note: Saving credentials in environment variables is convenient, but not\n",
    "    # secure - consider a more secure solution such as\n",
    "    # Cloud Secret Manager (https://cloud.google.com/secret-manager) to help\n",
    "    # keep secrets safe.\n",
    "\n",
    "    instance_connection_name = os.environ[\n",
    "        \"INSTANCE_CONNECTION_NAME\"\n",
    "    ]  # e.g. 'project:region:instance'\n",
    "    db_user = os.environ[\"DB_USER\"]  # e.g. 'my-db-user'\n",
    "    db_pass = os.environ[\"DB_PASS\"]  # e.g. 'my-db-password'\n",
    "    db_name = os.environ[\"DB_NAME\"]  # e.g. 'my-database'\n",
    "\n",
    "    ip_type = IPTypes.PRIVATE if os.environ.get(\"PRIVATE_IP\") else IPTypes.PUBLIC\n",
    "\n",
    "    # initialize Cloud SQL Python Connector object\n",
    "    connector = Connector()\n",
    "\n",
    "    def getconn() -> pg8000.dbapi.Connection:\n",
    "        conn: pg8000.dbapi.Connection = connector.connect(\n",
    "            instance_connection_name,\n",
    "            \"pg8000\",\n",
    "            user=db_user,\n",
    "            password=db_pass,\n",
    "            db=db_name,\n",
    "            ip_type=ip_type,\n",
    "        )\n",
    "        return conn\n",
    "\n",
    "    # The Cloud SQL Python Connector can be used with SQLAlchemy\n",
    "    # using the 'creator' argument to 'create_engine'\n",
    "    pool = sqlalchemy.create_engine(\n",
    "        \"postgresql+pg8000://\",\n",
    "        creator=getconn,\n",
    "        # ...\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/GitHub/vectrix/.venv/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "PostgreSQL version: PostgreSQL 15.7 on x86_64-pc-linux-gnu, compiled by Debian clang version 12.0.1, 64-bit\n",
      "Tables in the database:\n",
      "- prompts\n",
      "- documents\n",
      "- checkpoints\n",
      "- writes\n"
     ]
    }
   ],
   "source": [
    "# Connecting\n",
    "def test_connection(pool):\n",
    "    try:\n",
    "        # Create a connection from the pool\n",
    "        with pool.connect() as connection:\n",
    "            # Execute a simple query\n",
    "            result = connection.execute(sqlalchemy.text(\"SELECT version();\"))\n",
    "            version = result.fetchone()[0]\n",
    "            print(\"Connection successful!\")\n",
    "            print(f\"PostgreSQL version: {version}\")\n",
    "\n",
    "            # You can add more test queries here if needed\n",
    "            # For example, listing all tables in the current schema:\n",
    "            result = connection.execute(sqlalchemy.text(\n",
    "                \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';\"\n",
    "            ))\n",
    "            tables = [row[0] for row in result]\n",
    "            print(\"Tables in the database:\")\n",
    "            for table in tables:\n",
    "                print(f\"- {table}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error connecting to the database:\")\n",
    "        print(e)\n",
    "\n",
    "# Get the connection pool\n",
    "pool = connect_with_connector()\n",
    "\n",
    "# Run the test\n",
    "test_connection(pool)\n",
    "\n",
    "# Don't forget to dispose of the pool when you're done\n",
    "pool.dispose()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
